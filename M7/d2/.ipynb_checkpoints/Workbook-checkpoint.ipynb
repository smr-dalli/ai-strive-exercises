{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "psychological-alarm",
   "metadata": {},
   "source": [
    "## Importing Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unnecessary-pressing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:42.520625Z",
     "start_time": "2021-03-28T20:32:42.518920Z"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "## I recommend the one above, because the following is more accurate but less efficient\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frank-monaco",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:43.990040Z",
     "start_time": "2021-03-28T20:32:42.522741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import spacy\\n\\n%load_ext nb_black\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\n# You can also load en_core_web_lg that has an higher accuracy but it's less efficient\\n#\\u00a0nlp = spacy.load(\\\"en_core_web_lg\\\")\";\n",
       "                var nbb_formatted_code = \"import spacy\\n\\n%load_ext nb_black\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\n# You can also load en_core_web_lg that has an higher accuracy but it's less efficient\\n# \\u00a0nlp = spacy.load(\\\"en_core_web_lg\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# You can also load en_core_web_lg that has an higher accuracy but it's less efficient\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brutal-usage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:43.994556Z",
     "start_time": "2021-03-28T20:32:43.991087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f8850258430>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f8860afcbe0>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f8860afcca0>)]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"print(nlp.pipeline)\";\n",
       "                var nbb_formatted_code = \"print(nlp.pipeline)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "marine-rescue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.015363Z",
     "start_time": "2021-03-28T20:32:43.995410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\\ndoc = nlp(u\\\"Hello, world. Antonio is learning Python.\\\")\";\n",
       "                var nbb_formatted_code = \"# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\\ndoc = nlp(u\\\"Hello, world. Antonio is learning Python.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\n",
    "doc = nlp(u\"Hello, world. Antonio is learning Python.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-prospect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.021660Z",
     "start_time": "2021-03-28T20:32:44.016337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      ",\n",
      "world\n",
      ".\n",
      "Antonio\n",
      "is\n",
      "learning\n",
      "Python\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"for token in doc:\\n    print(token.text)\";\n",
       "                var nbb_formatted_code = \"for token in doc:\\n    print(token.text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fleet-shooting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.030363Z",
     "start_time": "2021-03-28T20:32:44.022649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello, world.\n",
      "Antonio is learning Python.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Get first token of the processed document\\ntoken = doc[0]\\nprint(token)\\n\\n# Print sentences (one sentence per line)\\nfor sent in doc.sents:\\n    print(sent)\";\n",
       "                var nbb_formatted_code = \"# Get first token of the processed document\\ntoken = doc[0]\\nprint(token)\\n\\n# Print sentences (one sentence per line)\\nfor sent in doc.sents:\\n    print(sent)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get first token of the processed document\n",
    "token = doc[0]\n",
    "print(token)\n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-intranet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.043811Z",
     "start_time": "2021-03-28T20:32:44.033898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"tokens = nlp(\\\"Let's go to N.Y.!\\\")\";\n",
       "                var nbb_formatted_code = \"tokens = nlp(\\\"Let's go to N.Y.!\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = nlp(\"Let's go to N.Y.!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designed-capitol",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.049403Z",
     "start_time": "2021-03-28T20:32:44.045680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"for token in tokens:\\n    print(token.text)\";\n",
       "                var nbb_formatted_code = \"for token in tokens:\\n    print(token.text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-duplicate",
   "metadata": {},
   "source": [
    "As you have seen, using `nlp`, that comes from `spacy.load(\"en_core_web_sm\")`, you get the tokenized version of the sentence. If you want only the instance of the `Tokenizer` class, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accomplished-marker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.054850Z",
     "start_time": "2021-03-28T20:32:44.050350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokenizer.Tokenizer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"tokenizer = nlp.tokenizer\\ntype(tokenizer)\";\n",
       "                var nbb_formatted_code = \"tokenizer = nlp.tokenizer\\ntype(tokenizer)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-medium",
   "metadata": {},
   "source": [
    "If you want to instantiate a custom one, with rules and prefixes and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "olive-mother",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.062007Z",
     "start_time": "2021-03-28T20:32:44.055855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from spacy.tokenizer import Tokenizer\\n\\ntokenizer = Tokenizer(vocab=nlp.vocab)\";\n",
       "                var nbb_formatted_code = \"from spacy.tokenizer import Tokenizer\\n\\ntokenizer = Tokenizer(vocab=nlp.vocab)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-clerk",
   "metadata": {},
   "source": [
    "The tokenizer defined above contains only english rules.\n",
    "Let's test it on \"Let's go to N.Y.!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinct-trade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.068307Z",
     "start_time": "2021-03-28T20:32:44.063416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's\n",
      "go\n",
      "to\n",
      "N.Y.!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"tokens = tokenizer(\\\"Let's go to N.Y.!\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"tokens = tokenizer(\\\"Let's go to N.Y.!\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = tokenizer(\"Let's go to N.Y.!\")\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-county",
   "metadata": {},
   "source": [
    "As you can see here, it doesn't handle the exceptions about the dots. So we can add rules for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opposed-confusion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.076430Z",
     "start_time": "2021-03-28T20:32:44.069248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\\nsuffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.prefixes)\";\n",
       "                var nbb_formatted_code = \"prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\\nsuffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.prefixes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "suffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "foster-highway",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.083023Z",
     "start_time": "2021-03-28T20:32:44.077855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"tokenizer = Tokenizer(\\n    vocab=nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\\n)\";\n",
       "                var nbb_formatted_code = \"tokenizer = Tokenizer(\\n    vocab=nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    vocab=nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adjacent-organ",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.088977Z",
     "start_time": "2021-03-28T20:32:44.083988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"tokens = tokenizer(\\\"Let's go to N.Y.!\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"tokens = tokenizer(\\\"Let's go to N.Y.!\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = tokenizer(\"Let's go to N.Y.!\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-provincial",
   "metadata": {},
   "source": [
    "You can also check the exceptions the tokenizer can handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exposed-compound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.103258Z",
     "start_time": "2021-03-28T20:32:44.092331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'m\", 73: 'be', 67: 'am', 75: 'VBP'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'm', 73: 'be', 75: 'VBP'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'m\", 73: 'be', 67: 'am'}, {65: 'a', 73: 'going to', 67: 'gonna'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'm', 73: 'be', 67: 'am'}, {65: 'a', 73: 'going to', 67: 'gonna'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'m\", 73: 'be', 67: 'am', 75: 'VBP'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'm', 73: 'be', 75: 'VBP'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'m\", 73: 'be', 67: 'am'}, {65: 'a', 73: 'going to', 67: 'gonna'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'm', 73: 'be', 67: 'am'}, {65: 'a', 73: 'going to', 67: 'gonna'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'d\", 67: \"'d\"}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'd', 67: \"'d\"}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'i', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'I', 73: '-PRON-', 67: 'i', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'you', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 're', 73: 'be', 67: 'are', 75: 'VBZ'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'You', 73: '-PRON-', 67: 'you', 75: 'PRP'}, {65: 're', 73: 'be', 67: 'are', 75: 'VBZ'}], [{65: 'we', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'We', 73: '-PRON-', 67: 'we', 75: 'PRP'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'they', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 're', 73: 'be', 67: 'are', 75: 'VBZ'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'They', 73: '-PRON-', 67: 'they', 75: 'PRP'}, {65: 're', 73: 'be', 67: 'are', 75: 'VBZ'}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'s\", 67: \"'s\"}], [{65: 'he', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 's'}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: \"'s\", 67: \"'s\"}], [{65: 'He', 73: '-PRON-', 67: 'he', 75: 'PRP'}, {65: 's'}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'s\", 67: \"'s\"}], [{65: 'she', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: 's'}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: \"'s\", 67: \"'s\"}], [{65: 'She', 73: '-PRON-', 67: 'she', 75: 'PRP'}, {65: 's'}], [{65: 'it', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'s\", 67: \"'s\"}], [{65: 'It', 73: '-PRON-', 67: 'it', 75: 'PRP'}, {65: \"'s\", 67: \"'s\"}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'s\", 67: \"'s\"}], [{65: 'who', 73: 'who', 67: 'who'}, {65: 's'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'who', 73: 'who'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'d\", 67: \"'d\"}], [{65: 'who', 73: 'who', 67: 'who'}, {65: 'd', 67: \"'d\"}], [{65: 'who', 73: 'who', 67: 'who'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'who', 73: 'who', 67: 'who'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: 's'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Who', 73: 'who'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: 'd', 67: \"'d\"}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Who', 73: 'who', 67: 'who'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'s\", 67: \"'s\"}], [{65: 'what', 73: 'what', 67: 'what'}, {65: 's'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'what', 73: 'what'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'d\", 67: \"'d\"}], [{65: 'what', 73: 'what', 67: 'what'}, {65: 'd', 67: \"'d\"}], [{65: 'what', 73: 'what', 67: 'what'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'what', 73: 'what', 67: 'what'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'s\", 67: \"'s\"}], [{65: 'What', 73: 'what', 67: 'what'}, {65: 's'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'What', 73: 'what'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'d\", 67: \"'d\"}], [{65: 'What', 73: 'what', 67: 'what'}, {65: 'd', 67: \"'d\"}], [{65: 'What', 73: 'what', 67: 'what'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'What', 73: 'what', 67: 'what'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'s\", 67: \"'s\"}], [{65: 'when', 73: 'when', 67: 'when'}, {65: 's'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'when', 73: 'when'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'d\", 67: \"'d\"}], [{65: 'when', 73: 'when', 67: 'when'}, {65: 'd', 67: \"'d\"}], [{65: 'when', 73: 'when', 67: 'when'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'when', 73: 'when', 67: 'when'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'s\", 67: \"'s\"}], [{65: 'When', 73: 'when', 67: 'when'}, {65: 's'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'When', 73: 'when'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'d\", 67: \"'d\"}], [{65: 'When', 73: 'when', 67: 'when'}, {65: 'd', 67: \"'d\"}], [{65: 'When', 73: 'when', 67: 'when'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'When', 73: 'when', 67: 'when'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'s\", 67: \"'s\"}], [{65: 'where', 73: 'where', 67: 'where'}, {65: 's'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'where', 73: 'where'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'d\", 67: \"'d\"}], [{65: 'where', 73: 'where', 67: 'where'}, {65: 'd', 67: \"'d\"}], [{65: 'where', 73: 'where', 67: 'where'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'where', 73: 'where', 67: 'where'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: 's'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Where', 73: 'where'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: 'd', 67: \"'d\"}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Where', 73: 'where', 67: 'where'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'s\", 67: \"'s\"}], [{65: 'why', 73: 'why', 67: 'why'}, {65: 's'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'why', 73: 'why'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'d\", 67: \"'d\"}], [{65: 'why', 73: 'why', 67: 'why'}, {65: 'd', 67: \"'d\"}], [{65: 'why', 73: 'why', 67: 'why'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'why', 73: 'why', 67: 'why'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: 's'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Why', 73: 'why'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: 'd', 67: \"'d\"}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Why', 73: 'why', 67: 'why'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'s\", 67: \"'s\"}], [{65: 'how', 73: 'how', 67: 'how'}, {65: 's'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'how', 73: 'how'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'d\", 67: \"'d\"}], [{65: 'how', 73: 'how', 67: 'how'}, {65: 'd', 67: \"'d\"}], [{65: 'how', 73: 'how', 67: 'how'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'how', 73: 'how', 67: 'how'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'s\", 67: \"'s\"}], [{65: 'How', 73: 'how', 67: 'how'}, {65: 's'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'How', 73: 'how'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'d\", 67: \"'d\"}], [{65: 'How', 73: 'how', 67: 'how'}, {65: 'd', 67: \"'d\"}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'s\", 67: \"'s\"}], [{65: 'there', 73: 'there', 67: 'there'}, {65: 's'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'there', 73: 'there'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'d\", 67: \"'d\"}], [{65: 'there', 73: 'there', 67: 'there'}, {65: 'd', 67: \"'d\"}], [{65: 'there', 73: 'there', 67: 'there'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'there', 73: 'there', 67: 'there'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'s\", 67: \"'s\"}], [{65: 'There', 73: 'there', 67: 'there'}, {65: 's'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'There', 73: 'there'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'d\", 67: \"'d\"}], [{65: 'There', 73: 'there', 67: 'there'}, {65: 'd', 67: \"'d\"}], [{65: 'There', 73: 'there', 67: 'there'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'There', 73: 'there', 67: 'there'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'s\", 67: \"'s\"}], [{65: 'that', 73: 'that', 67: 'that'}, {65: 's'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'that', 73: 'that'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'d\", 67: \"'d\"}], [{65: 'that', 73: 'that', 67: 'that'}, {65: 'd', 67: \"'d\"}], [{65: 'that', 73: 'that', 67: 'that'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'that', 73: 'that', 67: 'that'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'s\", 67: \"'s\"}], [{65: 'That', 73: 'that', 67: 'that'}, {65: 's'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'That', 73: 'that'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'d\", 67: \"'d\"}], [{65: 'That', 73: 'that', 67: 'that'}, {65: 'd', 67: \"'d\"}], [{65: 'That', 73: 'that', 67: 'that'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'That', 73: 'that', 67: 'that'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'s\", 67: \"'s\"}], [{65: 'this', 73: 'this', 67: 'this'}, {65: 's'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'this', 73: 'this'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'d\", 67: \"'d\"}], [{65: 'this', 73: 'this', 67: 'this'}, {65: 'd', 67: \"'d\"}], [{65: 'this', 73: 'this', 67: 'this'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'this', 73: 'this', 67: 'this'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'s\", 67: \"'s\"}], [{65: 'This', 73: 'this', 67: 'this'}, {65: 's'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'This', 73: 'this'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'d\", 67: \"'d\"}], [{65: 'This', 73: 'this', 67: 'this'}, {65: 'd', 67: \"'d\"}], [{65: 'This', 73: 'this', 67: 'this'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'This', 73: 'this', 67: 'this'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'s\", 67: \"'s\"}], [{65: 'these', 73: 'these', 67: 'these'}, {65: 's'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'these', 73: 'these'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'d\", 67: \"'d\"}], [{65: 'these', 73: 'these', 67: 'these'}, {65: 'd', 67: \"'d\"}], [{65: 'these', 73: 'these', 67: 'these'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'these', 73: 'these', 67: 'these'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'s\", 67: \"'s\"}], [{65: 'These', 73: 'these', 67: 'these'}, {65: 's'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'These', 73: 'these'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'d\", 67: \"'d\"}], [{65: 'These', 73: 'these', 67: 'these'}, {65: 'd', 67: \"'d\"}], [{65: 'These', 73: 'these', 67: 'these'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'These', 73: 'these', 67: 'these'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'s\", 67: \"'s\"}], [{65: 'those', 73: 'those', 67: 'those'}, {65: 's'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'those', 73: 'those'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'d\", 67: \"'d\"}], [{65: 'those', 73: 'those', 67: 'those'}, {65: 'd', 67: \"'d\"}], [{65: 'those', 73: 'those', 67: 'those'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'those', 73: 'those', 67: 'those'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'s\", 67: \"'s\"}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: 's'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'ll\", 73: 'will', 67: 'will', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: 'll', 73: 'will', 67: 'will', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'re\", 73: 'be', 67: 'are'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: 're', 73: 'be', 67: 'are'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Those', 73: 'those'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'d\", 67: \"'d\"}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: 'd', 67: \"'d\"}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: \"'d\", 73: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Those', 73: 'those', 67: 'those'}, {65: 'd', 73: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Ca', 73: 'can', 67: 'can', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'could', 67: 'could', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'could', 67: 'could', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'could', 67: 'could', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'could', 67: 'could', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Could', 67: 'could', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Could', 67: 'could', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Could', 67: 'could', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Could', 67: 'could', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'do', 73: 'do', 67: 'do'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'do', 73: 'do', 67: 'do'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'do', 73: 'do', 67: 'do'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'do', 73: 'do', 67: 'do'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Do', 73: 'do', 67: 'do'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Do', 73: 'do', 67: 'do'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Do', 73: 'do', 67: 'do'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Do', 73: 'do', 67: 'do'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'does', 73: 'do', 67: 'does'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'does', 73: 'do', 67: 'does'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'does', 73: 'do', 67: 'does'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'does', 73: 'do', 67: 'does'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Does', 73: 'do', 67: 'does'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Does', 73: 'do', 67: 'does'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Does', 73: 'do', 67: 'does'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Does', 73: 'do', 67: 'does'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Did', 73: 'do', 67: 'do', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Had', 73: 'have', 67: 'have', 75: 'VBD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'may', 67: 'may', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'may', 67: 'may', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'may', 67: 'may', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'may', 67: 'may', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'May', 67: 'may', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'May', 67: 'may', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'May', 67: 'may', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'May', 67: 'may', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'might', 67: 'might', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'might', 67: 'might', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'might', 67: 'might', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'might', 67: 'might', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Might', 67: 'might', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Might', 67: 'might', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Might', 67: 'might', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Might', 67: 'might', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'must', 67: 'must', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'must', 67: 'must', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'must', 67: 'must', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'must', 67: 'must', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Must', 67: 'must', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Must', 67: 'must', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Must', 67: 'must', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Must', 67: 'must', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'need', 67: 'need'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'need', 67: 'need'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'need', 67: 'need'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'need', 67: 'need'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Need', 67: 'need'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Need', 67: 'need'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Need', 67: 'need'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Need', 67: 'need'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'ought', 67: 'ought', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'ought', 67: 'ought', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'ought', 67: 'ought', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'ought', 67: 'ought', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Ought', 67: 'ought', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Ought', 67: 'ought', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Ought', 67: 'ought', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Ought', 67: 'ought', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Sha', 73: 'shall', 67: 'shall', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'should', 67: 'should', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'should', 67: 'should', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'should', 67: 'should', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'should', 67: 'should', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Should', 67: 'should', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Should', 67: 'should', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Should', 67: 'should', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Should', 67: 'should', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Wo', 73: 'will', 67: 'will', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'would', 67: 'would', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'would', 67: 'would', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'would', 67: 'would', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'would', 67: 'would', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Would', 67: 'would', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Would', 67: 'would', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Would', 67: 'would', 75: 'MD'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Would', 67: 'would', 75: 'MD'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'could', 67: 'could', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'could', 67: 'could', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'Could', 67: 'could', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Could', 67: 'could', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'might', 67: 'might', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'might', 67: 'might', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'Might', 67: 'might', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Might', 67: 'might', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'must', 67: 'must', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'must', 67: 'must', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'Must', 67: 'must', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Must', 67: 'must', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'should', 67: 'should', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'should', 67: 'should', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'Should', 67: 'should', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Should', 67: 'should', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'Would', 67: 'would', 75: 'MD'}, {65: \"'ve\", 73: 'have', 75: 'VB'}], [{65: 'Would', 67: 'would', 75: 'MD'}, {65: 've', 73: 'have', 75: 'VB'}], [{65: 'ai', 73: 'be', 75: 'VBP'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'ai', 73: 'be', 75: 'VBP'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Ai', 73: 'be', 75: 'VBP'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Ai', 73: 'be', 75: 'VBP'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'are', 73: 'be', 67: 'are', 75: 'VBP'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'are', 73: 'be', 67: 'are', 75: 'VBP'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Are', 73: 'be', 67: 'are', 75: 'VBP'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Are', 73: 'be', 67: 'are', 75: 'VBP'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'is', 73: 'be', 67: 'is', 75: 'VBZ'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'is', 73: 'be', 67: 'is', 75: 'VBZ'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Is', 73: 'be', 67: 'is', 75: 'VBZ'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Is', 73: 'be', 67: 'is', 75: 'VBZ'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'was', 73: 'be', 67: 'was'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'was', 73: 'be', 67: 'was'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Was', 73: 'be', 67: 'was'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Was', 73: 'be', 67: 'was'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'were', 73: 'be', 67: 'were'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'were', 73: 'be', 67: 'were'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Were', 73: 'be', 67: 'were'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Were', 73: 'be', 67: 'were'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'have', 67: 'have'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'have', 67: 'have'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Have', 67: 'have'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Have', 67: 'have'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'has', 73: 'have', 67: 'has'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'has', 73: 'have', 67: 'has'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Has', 73: 'have', 67: 'has'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Has', 73: 'have', 67: 'has'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'dare', 67: 'dare'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'dare', 67: 'dare'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Dare', 67: 'dare'}, {65: \"n't\", 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'Dare', 67: 'dare'}, {65: 'nt', 73: 'not', 67: 'not', 75: 'RB'}], [{65: 'doin', 73: 'do', 67: 'doing'}], [{65: \"doin'\", 73: 'do', 67: 'doing'}], [{65: 'Doin', 73: 'do', 67: 'doing'}], [{65: \"Doin'\", 73: 'do', 67: 'doing'}], [{65: 'goin', 73: 'go', 67: 'going'}], [{65: \"goin'\", 73: 'go', 67: 'going'}], [{65: 'Goin', 73: 'go', 67: 'going'}], [{65: \"Goin'\", 73: 'go', 67: 'going'}], [{65: 'nothin', 73: 'nothing', 67: 'nothing'}], [{65: \"nothin'\", 73: 'nothing', 67: 'nothing'}], [{65: 'Nothin', 73: 'nothing', 67: 'nothing'}], [{65: \"Nothin'\", 73: 'nothing', 67: 'nothing'}], [{65: 'nuthin', 73: 'nothing', 67: 'nothing'}], [{65: \"nuthin'\", 73: 'nothing', 67: 'nothing'}], [{65: 'Nuthin', 73: 'nothing', 67: 'nothing'}], [{65: \"Nuthin'\", 73: 'nothing', 67: 'nothing'}], [{65: 'ol', 73: 'old', 67: 'old'}], [{65: \"ol'\", 73: 'old', 67: 'old'}], [{65: 'Ol', 73: 'old', 67: 'old'}], [{65: \"Ol'\", 73: 'old', 67: 'old'}], [{65: 'somethin', 73: 'something', 67: 'something'}], [{65: \"somethin'\", 73: 'something', 67: 'something'}], [{65: 'Somethin', 73: 'something', 67: 'something'}], [{65: \"Somethin'\", 73: 'something', 67: 'something'}], [{65: 'cause', 67: 'because'}], [{65: \"'cause\", 73: 'because', 67: 'because'}], [{65: 'em', 73: '-PRON-', 67: 'them'}], [{65: \"'em\", 73: '-PRON-', 67: 'them'}], [{65: 'll', 73: 'will', 67: 'will'}], [{65: \"'ll\", 73: 'will', 67: 'will'}], [{65: 'nuff', 73: 'enough', 67: 'enough'}], [{65: \"'nuff\", 73: 'enough', 67: 'enough'}], [{65: '1'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '1'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '1'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '1'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '2'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '2'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '2'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '2'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '3'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '3'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '3'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '3'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '4'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '4'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '4'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '4'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '5'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '5'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '5'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '5'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '6'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '6'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '6'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '6'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '7'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '7'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '7'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '7'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '8'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '8'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '8'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '8'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '9'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '9'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '9'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '9'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '10'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '10'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '10'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '10'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '11'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '11'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '11'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '11'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: '12'}, {65: 'a.m.', 73: 'a.m.', 67: 'a.m.'}], [{65: '12'}, {65: 'am', 73: 'a.m.', 67: 'a.m.'}], [{65: '12'}, {65: 'p.m.', 73: 'p.m.', 67: 'p.m.'}], [{65: '12'}, {65: 'pm', 73: 'p.m.', 67: 'p.m.'}], [{65: \"y'\", 73: '-PRON-', 67: 'you'}, {65: 'all'}], [{65: 'y', 73: '-PRON-', 67: 'you'}, {65: 'all'}], [{65: 'how', 73: 'how'}, {65: \"'d\", 73: 'do'}, {65: \"'y\", 73: '-PRON-', 67: 'you'}], [{65: 'How', 73: 'how', 67: 'how'}, {65: \"'d\", 73: 'do'}, {65: \"'y\", 73: '-PRON-', 67: 'you'}], [{65: 'not', 73: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'not', 73: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Not', 73: 'not', 67: 'not', 75: 'RB'}, {65: \"'ve\", 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'Not', 73: 'not', 67: 'not', 75: 'RB'}, {65: 've', 73: 'have', 67: 'have', 75: 'VB'}], [{65: 'can', 73: 'can', 75: 'MD'}, {65: 'not', 73: 'not', 75: 'RB'}], [{65: 'Can', 73: 'can', 67: 'can', 75: 'MD'}, {65: 'not', 73: 'not', 75: 'RB'}], [{65: 'gon', 73: 'go', 67: 'going'}, {65: 'na', 73: 'to', 67: 'to'}], [{65: 'Gon', 73: 'go', 67: 'going'}, {65: 'na', 73: 'to', 67: 'to'}], [{65: 'got'}, {65: 'ta', 73: 'to', 67: 'to'}], [{65: 'Got', 67: 'got'}, {65: 'ta', 73: 'to', 67: 'to'}], [{65: 'let'}, {65: \"'s\", 73: '-PRON-', 67: 'us'}], [{65: 'Let', 73: 'let', 67: 'let'}, {65: \"'s\", 73: '-PRON-', 67: 'us'}], [{65: \"c'm\", 67: 'come', 73: 'come'}, {65: 'on'}], [{65: \"C'm\", 67: 'come', 73: 'come'}, {65: 'on'}], [{65: \"'S\", 73: \"'s\", 67: \"'s\"}], [{65: \"'s\", 73: \"'s\", 67: \"'s\"}], [{65: '‘S', 73: \"'s\", 67: \"'s\"}], [{65: '‘s', 73: \"'s\", 67: \"'s\"}], [{65: 'and/or', 73: 'and/or', 67: 'and/or', 75: 'CC'}], [{65: 'w/o', 73: 'without', 67: 'without'}], [{65: \"'re\", 73: 'be', 67: 'are'}], [{65: \"'Cause\", 73: 'because', 67: 'because'}], [{65: \"'cos\", 73: 'because', 67: 'because'}], [{65: \"'Cos\", 73: 'because', 67: 'because'}], [{65: \"'coz\", 73: 'because', 67: 'because'}], [{65: \"'Coz\", 73: 'because', 67: 'because'}], [{65: \"'cuz\", 73: 'because', 67: 'because'}], [{65: \"'Cuz\", 73: 'because', 67: 'because'}], [{65: \"'bout\", 73: 'about', 67: 'about'}], [{65: \"ma'am\", 73: 'madam', 67: 'madam'}], [{65: \"Ma'am\", 73: 'madam', 67: 'madam'}], [{65: \"o'clock\", 73: \"o'clock\", 67: \"o'clock\"}], [{65: \"O'clock\", 73: \"o'clock\", 67: \"o'clock\"}], [{65: \"lovin'\", 73: 'love', 67: 'loving'}], [{65: \"Lovin'\", 73: 'love', 67: 'loving'}], [{65: 'lovin', 73: 'love', 67: 'loving'}], [{65: 'Lovin', 73: 'love', 67: 'loving'}], [{65: \"havin'\", 73: 'have', 67: 'having'}], [{65: \"Havin'\", 73: 'have', 67: 'having'}], [{65: 'havin', 73: 'have', 67: 'having'}], [{65: 'Havin', 73: 'have', 67: 'having'}], [{65: 'Mt.', 73: 'Mount', 67: 'Mount'}], [{65: 'Ak.', 73: 'Alaska', 67: 'Alaska'}], [{65: 'Ala.', 73: 'Alabama', 67: 'Alabama'}], [{65: 'Apr.', 73: 'April', 67: 'April'}], [{65: 'Ariz.', 73: 'Arizona', 67: 'Arizona'}], [{65: 'Ark.', 73: 'Arkansas', 67: 'Arkansas'}], [{65: 'Aug.', 73: 'August', 67: 'August'}], [{65: 'Calif.', 73: 'California', 67: 'California'}], [{65: 'Colo.', 73: 'Colorado', 67: 'Colorado'}], [{65: 'Conn.', 73: 'Connecticut', 67: 'Connecticut'}], [{65: 'Dec.', 73: 'December', 67: 'December'}], [{65: 'Del.', 73: 'Delaware', 67: 'Delaware'}], [{65: 'Feb.', 73: 'February', 67: 'February'}], [{65: 'Fla.', 73: 'Florida', 67: 'Florida'}], [{65: 'Ga.', 73: 'Georgia', 67: 'Georgia'}], [{65: 'Ia.', 73: 'Iowa', 67: 'Iowa'}], [{65: 'Id.', 73: 'Idaho', 67: 'Idaho'}], [{65: 'Ill.', 73: 'Illinois', 67: 'Illinois'}], [{65: 'Ind.', 73: 'Indiana', 67: 'Indiana'}], [{65: 'Jan.', 73: 'January', 67: 'January'}], [{65: 'Jul.', 73: 'July', 67: 'July'}], [{65: 'Jun.', 73: 'June', 67: 'June'}], [{65: 'Kan.', 73: 'Kansas', 67: 'Kansas'}], [{65: 'Kans.', 73: 'Kansas', 67: 'Kansas'}], [{65: 'Ky.', 73: 'Kentucky', 67: 'Kentucky'}], [{65: 'La.', 73: 'Louisiana', 67: 'Louisiana'}], [{65: 'Mar.', 73: 'March', 67: 'March'}], [{65: 'Mass.', 73: 'Massachusetts', 67: 'Massachusetts'}], [{65: 'May.', 73: 'May', 67: 'May'}], [{65: 'Mich.', 73: 'Michigan', 67: 'Michigan'}], [{65: 'Minn.', 73: 'Minnesota', 67: 'Minnesota'}], [{65: 'Miss.', 73: 'Mississippi', 67: 'Mississippi'}], [{65: 'N.C.', 73: 'North Carolina', 67: 'North Carolina'}], [{65: 'N.D.', 73: 'North Dakota', 67: 'North Dakota'}], [{65: 'N.H.', 73: 'New Hampshire', 67: 'New Hampshire'}], [{65: 'N.J.', 73: 'New Jersey', 67: 'New Jersey'}], [{65: 'N.M.', 73: 'New Mexico', 67: 'New Mexico'}], [{65: 'N.Y.', 73: 'New York', 67: 'New York'}], [{65: 'Neb.', 73: 'Nebraska', 67: 'Nebraska'}], [{65: 'Nebr.', 73: 'Nebraska', 67: 'Nebraska'}], [{65: 'Nev.', 73: 'Nevada', 67: 'Nevada'}], [{65: 'Nov.', 73: 'November', 67: 'November'}], [{65: 'Oct.', 73: 'October', 67: 'October'}], [{65: 'Okla.', 73: 'Oklahoma', 67: 'Oklahoma'}], [{65: 'Ore.', 73: 'Oregon', 67: 'Oregon'}], [{65: 'Pa.', 73: 'Pennsylvania', 67: 'Pennsylvania'}], [{65: 'S.C.', 73: 'South Carolina', 67: 'South Carolina'}], [{65: 'Sep.', 73: 'September', 67: 'September'}], [{65: 'Sept.', 73: 'September', 67: 'September'}], [{65: 'Tenn.', 73: 'Tennessee', 67: 'Tennessee'}], [{65: 'Va.', 73: 'Virginia', 67: 'Virginia'}], [{65: 'Wash.', 73: 'Washington', 67: 'Washington'}], [{65: 'Wis.', 73: 'Wisconsin', 67: 'Wisconsin'}], [{65: \"'d\"}], [{65: 'a.m.'}], [{65: 'Adm.'}], [{65: 'Bros.'}], [{65: 'co.'}], [{65: 'Co.'}], [{65: 'Corp.'}], [{65: 'D.C.'}], [{65: 'Dr.'}], [{65: 'e.g.'}], [{65: 'E.g.'}], [{65: 'E.G.'}], [{65: 'Gen.'}], [{65: 'Gov.'}], [{65: 'i.e.'}], [{65: 'I.e.'}], [{65: 'I.E.'}], [{65: 'Inc.'}], [{65: 'Jr.'}], [{65: 'Ltd.'}], [{65: 'Md.'}], [{65: 'Messrs.'}], [{65: 'Mo.'}], [{65: 'Mont.'}], [{65: 'Mr.'}], [{65: 'Mrs.'}], [{65: 'Ms.'}], [{65: 'p.m.'}], [{65: 'Ph.D.'}], [{65: 'Prof.'}], [{65: 'Rep.'}], [{65: 'Rev.'}], [{65: 'Sen.'}], [{65: 'St.'}], [{65: 'vs.'}], [{65: 'v.s.'}]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"from spacy.lang.en.tokenizer_exceptions import TOKENIZER_EXCEPTIONS\\n\\nTOKENIZER_EXCEPTIONS.values()\";\n",
       "                var nbb_formatted_code = \"from spacy.lang.en.tokenizer_exceptions import TOKENIZER_EXCEPTIONS\\n\\nTOKENIZER_EXCEPTIONS.values()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.lang.en.tokenizer_exceptions import TOKENIZER_EXCEPTIONS\n",
    "\n",
    "TOKENIZER_EXCEPTIONS.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "excess-rebound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.109723Z",
     "start_time": "2021-03-28T20:32:44.104174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "$\n",
      "STOCK.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"tokens = tokenizer(\\\"This is a $STOCK.\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"tokens = tokenizer(\\\"This is a $STOCK.\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = tokenizer(\"This is a $STOCK.\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-adaptation",
   "metadata": {},
   "source": [
    "You can add special prefixes in the form of regex by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unlikely-croatia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.115930Z",
     "start_time": "2021-03-28T20:32:44.111815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"custom_prefixes = nlp.Defaults.prefixes + (r\\\"\\\\$[a-zA-Z]+\\\",)\";\n",
       "                var nbb_formatted_code = \"custom_prefixes = nlp.Defaults.prefixes + (r\\\"\\\\$[a-zA-Z]+\\\",)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_prefixes = nlp.Defaults.prefixes + (r\"\\$[a-zA-Z]+\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "strategic-slovakia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.124436Z",
     "start_time": "2021-03-28T20:32:44.117070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"prefix_re = spacy.util.compile_prefix_regex(custom_prefixes)\";\n",
       "                var nbb_formatted_code = \"prefix_re = spacy.util.compile_prefix_regex(custom_prefixes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prefix_re = spacy.util.compile_prefix_regex(custom_prefixes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arabic-arena",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.134261Z",
     "start_time": "2021-03-28T20:32:44.125454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "$STOCK\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"import re\\n\\nprefix_re = re.compile(r\\\"\\\\$[a-zA-Z]+\\\")\\ntokenizer = Tokenizer(\\n    nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\\n)\\n\\ntokens = tokenizer(\\\"This is a $STOCK.\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"import re\\n\\nprefix_re = re.compile(r\\\"\\\\$[a-zA-Z]+\\\")\\ntokenizer = Tokenizer(\\n    nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\\n)\\n\\ntokens = tokenizer(\\\"This is a $STOCK.\\\")\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "prefix_re = re.compile(r\"\\$[a-zA-Z]+\")\n",
    "tokenizer = Tokenizer(\n",
    "    nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search\n",
    ")\n",
    "\n",
    "tokens = tokenizer(\"This is a $STOCK.\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-breed",
   "metadata": {},
   "source": [
    "You can add also special-case tokenization rules. This mechanism is also used to add custom tokenizer exceptions to the language data. See the usage guide on the [languages data](https://spacy.io/usage/linguistic-features#language-data) and [tokenizer special cases](https://spacy.io/usage/linguistic-features#special-cases) for more details and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dirty-chester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.146952Z",
     "start_time": "2021-03-28T20:32:44.135427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "!\n",
      "give\n",
      "me\n",
      "five\n",
      "!\n",
      "you\n",
      "do\n",
      "not\n",
      "do\n",
      "that\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"from spacy.attrs import ORTH, NORM, LOWER\\n\\ndont_case = [{ORTH: \\\"do\\\"}, {ORTH: \\\"n't\\\", NORM: \\\"not\\\"}]\\ngimme_case = [{ORTH: \\\"gi\\\", NORM:\\\"give\\\"}, {ORTH: \\\"me\\\", NORM: \\\"me\\\"}]\\ntokenizer.add_special_case(\\\"don't\\\", dont_case)\\ntokenizer.add_special_case(\\\"gimme\\\", gimme_case)\\ntokens = tokenizer(\\\"Yo! gimme five!\\\")\\nfor token in tokens:\\n    print(token.norm_)\\ntokens = tokenizer(\\\"You don't do that\\\")\\nfor token in tokens:\\n    print(token.norm_)\";\n",
       "                var nbb_formatted_code = \"from spacy.attrs import ORTH, NORM, LOWER\\n\\ndont_case = [{ORTH: \\\"do\\\"}, {ORTH: \\\"n't\\\", NORM: \\\"not\\\"}]\\ngimme_case = [{ORTH: \\\"gi\\\", NORM: \\\"give\\\"}, {ORTH: \\\"me\\\", NORM: \\\"me\\\"}]\\ntokenizer.add_special_case(\\\"don't\\\", dont_case)\\ntokenizer.add_special_case(\\\"gimme\\\", gimme_case)\\ntokens = tokenizer(\\\"Yo! gimme five!\\\")\\nfor token in tokens:\\n    print(token.norm_)\\ntokens = tokenizer(\\\"You don't do that\\\")\\nfor token in tokens:\\n    print(token.norm_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.attrs import ORTH, NORM, LOWER\n",
    "\n",
    "dont_case = [{ORTH: \"do\"}, {ORTH: \"n't\", NORM: \"not\"}]\n",
    "gimme_case = [{ORTH: \"gi\", NORM:\"give\"}, {ORTH: \"me\", NORM: \"me\"}]\n",
    "tokenizer.add_special_case(\"don't\", dont_case)\n",
    "tokenizer.add_special_case(\"gimme\", gimme_case)\n",
    "tokens = tokenizer(\"Yo! gimme five!\")\n",
    "for token in tokens:\n",
    "    print(token.norm_)\n",
    "tokens = tokenizer(\"You don't do that\")\n",
    "for token in tokens:\n",
    "    print(token.norm_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-checklist",
   "metadata": {},
   "source": [
    "When you load a model with pretrained NER (Named Entity Recognition), like `en_core_web_sm`, it is possible to make the tokenizer to merge the token for the entities it finds. Let's check what is inside the pipeline performed by `nlp`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "undefined-jesus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.151274Z",
     "start_time": "2021-03-28T20:32:44.148001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f8850258430>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f8860afcbe0>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f8860afcca0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"nlp.pipeline\";\n",
       "                var nbb_formatted_code = \"nlp.pipeline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-consumer",
   "metadata": {},
   "source": [
    "There's a tagger, a dependency parser and the entity recognizer. Let's check the entities of the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sufficient-radar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.161196Z",
     "start_time": "2021-03-28T20:32:44.152194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"doc = nlp(\\\"Apple is a $1000b company.\\\")\";\n",
       "                var nbb_formatted_code = \"doc = nlp(\\\"Apple is a $1000b company.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Apple is a $1000b company.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mighty-twenty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.166456Z",
     "start_time": "2021-03-28T20:32:44.162183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "a\n",
      "$\n",
      "1000b\n",
      "company\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"for token in doc:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"for token in doc:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "convenient-census",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.172302Z",
     "start_time": "2021-03-28T20:32:44.167426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "1000b MONEY\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"for ent in doc.ents:\\n    print(ent, ent.label_)\";\n",
       "                var nbb_formatted_code = \"for ent in doc.ents:\\n    print(ent, ent.label_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pregnant-working",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.200653Z",
     "start_time": "2021-03-28T20:32:44.178705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "Strive\n",
      "School\n",
      ".\n",
      "It\n",
      "'s\n",
      "worthy\n",
      "to\n",
      "merge\n",
      "'\n",
      "Strive\n",
      "School\n",
      "'\n",
      "as\n",
      "a\n",
      "single\n",
      "token\n",
      "instead\n",
      "of\n",
      "two\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"doc = nlp(\\n    \\\"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\\\"\\n)\\n\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"doc = nlp(\\n    \\\"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\\\"\\n)\\n\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sweet-mandate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.207796Z",
     "start_time": "2021-03-28T20:32:44.203763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strive School ORG\n",
      "Strive School' ORG\n",
      "two CARDINAL\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"for ent in doc.ents:\\n    print(ent, ent.label_)\";\n",
       "                var nbb_formatted_code = \"for ent in doc.ents:\\n    print(ent, ent.label_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-calculator",
   "metadata": {},
   "source": [
    "Let's add \"merge_entities\" to the pipeline (you can do it only if there is the entity recognizer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "laughing-military",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.212102Z",
     "start_time": "2021-03-28T20:32:44.208805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"nlp.add_pipe(nlp.create_pipe(\\\"merge_entities\\\"))\";\n",
       "                var nbb_formatted_code = \"nlp.add_pipe(nlp.create_pipe(\\\"merge_entities\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.add_pipe(nlp.create_pipe(\"merge_entities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "standing-textbook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.216239Z",
     "start_time": "2021-03-28T20:32:44.213031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f8850258430>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f8860afcbe0>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f8860afcca0>),\n",
       " ('merge_entities', <function spacy.pipeline.functions.merge_entities(doc)>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"nlp.pipeline\";\n",
       "                var nbb_formatted_code = \"nlp.pipeline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "determined-montana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.233121Z",
     "start_time": "2021-03-28T20:32:44.217083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "Strive School\n",
      ".\n",
      "It\n",
      "'s\n",
      "worthy\n",
      "to\n",
      "merge\n",
      "'\n",
      "Strive School'\n",
      "as\n",
      "a\n",
      "single\n",
      "token\n",
      "instead\n",
      "of\n",
      "two\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"doc = nlp(\\n    \\\"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\\\"\\n)\\n\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"doc = nlp(\\n    \\\"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\\\"\\n)\\n\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"This is Strive School. It's worthy to merge 'Strive School' as a single token instead of two\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stretch-solution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.237660Z",
     "start_time": "2021-03-28T20:32:44.234118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"TEXTS = [\\n    \\\"Net income was $9.4 million compared to the prior year of $2.7 million.\\\",\\n    \\\"Revenue exceeded twelve billion dollars, with a loss of $1b.\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"TEXTS = [\\n    \\\"Net income was $9.4 million compared to the prior year of $2.7 million.\\\",\\n    \\\"Revenue exceeded twelve billion dollars, with a loss of $1b.\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEXTS = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "informal-petite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.257141Z",
     "start_time": "2021-03-28T20:32:44.238468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net\n",
      "income\n",
      "was\n",
      "$9.4 million\n",
      "compared\n",
      "to\n",
      "the prior year\n",
      "of\n",
      "$2.7 million\n",
      ".\n",
      "------------------\n",
      "Revenue\n",
      "exceeded\n",
      "twelve billion dollars\n",
      ",\n",
      "with\n",
      "a\n",
      "loss\n",
      "of\n",
      "$\n",
      "1b\n",
      ".\n",
      "------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"for sentence in nlp.pipe(TEXTS):\\n    for token in sentence:\\n        print(token)\\n    print(\\\"------------------\\\")\";\n",
       "                var nbb_formatted_code = \"for sentence in nlp.pipe(TEXTS):\\n    for token in sentence:\\n        print(token)\\n    print(\\\"------------------\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sentence in nlp.pipe(TEXTS):\n",
    "    for token in sentence:\n",
    "        print(token)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-maximum",
   "metadata": {},
   "source": [
    "It's also possible to merge the noun chunks into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "possible-client",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.263274Z",
     "start_time": "2021-03-28T20:32:44.258469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"nlp.add_pipe(nlp.create_pipe(\\\"merge_noun_chunks\\\"))\";\n",
       "                var nbb_formatted_code = \"nlp.add_pipe(nlp.create_pipe(\\\"merge_noun_chunks\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.add_pipe(nlp.create_pipe(\"merge_noun_chunks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "frozen-custody",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.268793Z",
     "start_time": "2021-03-28T20:32:44.264555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f8850258430>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f8860afcbe0>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f8860afcca0>),\n",
       " ('merge_entities', <function spacy.pipeline.functions.merge_entities(doc)>),\n",
       " ('merge_noun_chunks',\n",
       "  <function spacy.pipeline.functions.merge_noun_chunks(doc)>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"nlp.pipeline\";\n",
       "                var nbb_formatted_code = \"nlp.pipeline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "every-wedding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.282564Z",
     "start_time": "2021-03-28T20:32:44.269711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      ",\n",
      "I\n",
      "'m\n",
      "Antonio Marsella\n",
      ",\n",
      "nice\n",
      "to\n",
      "meet\n",
      "you\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"doc = nlp(\\\"Hello, I'm Antonio Marsella, nice to meet you.\\\")\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"doc = nlp(\\\"Hello, I'm Antonio Marsella, nice to meet you.\\\")\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Hello, I'm Antonio Marsella, nice to meet you.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-cassette",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-brief",
   "metadata": {},
   "source": [
    "In general, it's convenient to remove all the stop words, *i.e. very common words in a language*, because they don't help most of NLP problem such as semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "going-palace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.290058Z",
     "start_time": "2021-03-28T20:32:44.283484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['front', 'within', 'down', 'besides', 'each', 'until', 'more', 'take', 'have', 'various']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\\nprint(\\\"Number of stop words: %d\\\" % len(spacy_stopwords))\\nprint(\\\"First ten stop words: %s\\\" % list(spacy_stopwords)[:10])\";\n",
       "                var nbb_formatted_code = \"spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\\nprint(\\\"Number of stop words: %d\\\" % len(spacy_stopwords))\\nprint(\\\"First ten stop words: %s\\\" % list(spacy_stopwords)[:10])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(\"Number of stop words: %d\" % len(spacy_stopwords))\n",
    "print(\"First ten stop words: %s\" % list(spacy_stopwords)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-tokyo",
   "metadata": {},
   "source": [
    "To remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "crucial-entry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:32:44.317300Z",
     "start_time": "2021-03-28T20:32:44.291085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determined\n",
      "drop\n",
      "his litigation\n",
      "the monastry\n",
      ",\n",
      "relinguish\n",
      "his claims\n",
      "wood\n",
      "-\n",
      "cuting\n",
      "\n",
      "\n",
      "fishery rihgts\n",
      ".\n",
      "ready\n",
      "this becuase\n",
      "the rights\n",
      "valuable\n",
      ",\n",
      "\n",
      "\n",
      "indeed the vaguest idea\n",
      "the wood\n",
      "river\n",
      "question\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"text = \\\"\\\"\\\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \\nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \\nindeed the vaguest idea where the wood and river in question were.\\\"\\\"\\\"\\n\\ndoc = nlp(text)\\n\\ntokens = [token.text for token in doc if not token.is_stop]\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"text = \\\"\\\"\\\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \\nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \\nindeed the vaguest idea where the wood and river in question were.\\\"\\\"\\\"\\n\\ndoc = nlp(text)\\n\\ntokens = [token.text for token in doc if not token.is_stop]\\nfor token in tokens:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "tokens = [token.text for token in doc if not token.is_stop]\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-death",
   "metadata": {},
   "source": [
    "For adding customized stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acknowledged-bahamas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:30.546200Z",
     "start_time": "2021-03-28T20:33:30.528780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"customize_stop_words = [\\\"computing\\\", \\\"filtered\\\"]\\nfor w in customize_stop_words:\\n    nlp.vocab[w].is_stop = True\";\n",
       "                var nbb_formatted_code = \"customize_stop_words = [\\\"computing\\\", \\\"filtered\\\"]\\nfor w in customize_stop_words:\\n    nlp.vocab[w].is_stop = True\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "customize_stop_words = [\"computing\", \"filtered\"]\n",
    "for w in customize_stop_words:\n",
    "    nlp.vocab[w].is_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-scene",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "In most natural languages, a root word can have many variants. For example, the word ‘play’ can be used as ‘playing’, ‘played’, ‘plays’, etc. You can think of similar examples (and there are plenty).\n",
    "\n",
    "**Stemming**\n",
    "\n",
    "Let’s first understand stemming:\n",
    "\n",
    "Stemming is a text normalization technique that cuts off the end or beginning of a word by taking into account a list of common prefixes or suffixes that could be found in that word\n",
    "It is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word\n",
    " \n",
    "\n",
    "**Lemmatization**\n",
    "\n",
    "Lemmatization, on the other hand, is an organized & step-by-step procedure of obtaining the root form of the word. It makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations).\n",
    "\n",
    "Stemming algorithm works by cutting the suffix or prefix from the word. Lemmatization is a more powerful operation as it takes into consideration the morphological analysis of the word.\n",
    "\n",
    "Lemmatization returns the lemma, which is the root word of all its inflection forms.\n",
    "\n",
    "We can say that stemming is a quick and dirty method of chopping off words to its root form while on the other hand, lemmatization is an intelligent operation that uses dictionaries which are created by in-depth linguistic knowledge. Hence, Lemmatization helps in forming better features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "worthy-toilet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:36.947990Z",
     "start_time": "2021-03-28T20:33:36.465998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['determine',\n",
       " 'drop',\n",
       " 'litigation',\n",
       " 'monastry',\n",
       " ',',\n",
       " 'relinguish',\n",
       " 'claim',\n",
       " 'wood',\n",
       " '-',\n",
       " 'cut',\n",
       " '\\n',\n",
       " 'fishery',\n",
       " 'rihgts',\n",
       " '.',\n",
       " 'ready',\n",
       " 'becuase',\n",
       " 'right',\n",
       " 'valuable',\n",
       " ',',\n",
       " '\\n',\n",
       " 'vague',\n",
       " 'idea',\n",
       " 'wood',\n",
       " 'river',\n",
       " 'question',\n",
       " '.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\nnlp.add_pipe(nlp.create_pipe(\\\"merge_entities\\\"))\\n# not using merge_chunk_nouns\\ndoc = nlp(\\n    u\\\"\\\"\\\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \\nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \\nindeed the vaguest idea where the wood and river in question were.\\\"\\\"\\\"\\n)\\n\\nlemma_word1 = []\\nfor token in doc:\\n    if token.is_stop:\\n        continue\\n    lemma_word1.append(token.lemma_)\\nlemma_word1\";\n",
       "                var nbb_formatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\nnlp.add_pipe(nlp.create_pipe(\\\"merge_entities\\\"))\\n# not using merge_chunk_nouns\\ndoc = nlp(\\n    u\\\"\\\"\\\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \\nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \\nindeed the vaguest idea where the wood and river in question were.\\\"\\\"\\\"\\n)\\n\\nlemma_word1 = []\\nfor token in doc:\\n    if token.is_stop:\\n        continue\\n    lemma_word1.append(token.lemma_)\\nlemma_word1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(nlp.create_pipe(\"merge_entities\"))\n",
    "# not using merge_chunk_nouns\n",
    "doc = nlp(\n",
    "    u\"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    ")\n",
    "\n",
    "lemma_word1 = []\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        continue\n",
    "    lemma_word1.append(token.lemma_)\n",
    "lemma_word1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-large",
   "metadata": {},
   "source": [
    "## Removing the punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tested-lafayette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:38.236544Z",
     "start_time": "2021-03-28T20:33:38.220156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He determined to drop his litigation with the monastry and relinguish his claims to the woodcuting and \\nfishery rihgts at once He was the more ready to do this becuase the rights had become much less valuable and he had \\nindeed the vaguest idea where the wood and river in question were'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"text = \\\"\\\"\\\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \\nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \\nindeed the vaguest idea where the wood and river in question were.\\\"\\\"\\\"\\n\\n\\nimport string\\n\\ntext_no_punct = \\\"\\\".join([char for char in text if char not in string.punctuation])\\n\\ntext_no_punct\";\n",
       "                var nbb_formatted_code = \"text = \\\"\\\"\\\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \\nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \\nindeed the vaguest idea where the wood and river in question were.\\\"\\\"\\\"\\n\\n\\nimport string\\n\\ntext_no_punct = \\\"\\\".join([char for char in text if char not in string.punctuation])\\n\\ntext_no_punct\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "\n",
    "import string\n",
    "\n",
    "text_no_punct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "text_no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "institutional-commerce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:33:38.840465Z",
     "start_time": "2021-03-28T20:33:38.808474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "determined\n",
      "to\n",
      "drop\n",
      "his\n",
      "litigation\n",
      "with\n",
      "the\n",
      "monastry\n",
      "and\n",
      "relinguish\n",
      "his\n",
      "claims\n",
      "to\n",
      "the\n",
      "woodcuting\n",
      "and\n",
      "\n",
      "\n",
      "fishery\n",
      "rihgts\n",
      "at\n",
      "once\n",
      "He\n",
      "was\n",
      "the\n",
      "more\n",
      "ready\n",
      "to\n",
      "do\n",
      "this\n",
      "becuase\n",
      "the\n",
      "rights\n",
      "had\n",
      "become\n",
      "much\n",
      "less\n",
      "valuable\n",
      "and\n",
      "he\n",
      "had\n",
      "\n",
      "\n",
      "indeed\n",
      "the\n",
      "vaguest\n",
      "idea\n",
      "where\n",
      "the\n",
      "wood\n",
      "and\n",
      "river\n",
      "in\n",
      "question\n",
      "were\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"doc = nlp(text_no_punct)\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_formatted_code = \"doc = nlp(text_no_punct)\\nfor token in doc:\\n    print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(text_no_punct)\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-source",
   "metadata": {},
   "source": [
    "For text extracted from dialogues or chats, it is convenient to preprocess the text so that multiple occurrences of the same characters get condensed into one or two, and then use a spell checker to find the correct form of the word.\n",
    "\n",
    "A way to do that is to replace all the occurrences of repeated characters with a single one and then use a spell checker: \"hhheeelllllooo hoooowww areee youuu?\" becomes \"helo how are you?\" and then the spell checker would make it \"hello how are you?\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "greater-cabin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:44:46.506377Z",
     "start_time": "2021-03-28T20:44:46.492492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heLo how are you?'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 99;\n",
       "                var nbb_unformatted_code = \"st = \\\"hhheeeLLLLooo hoooowww areee youuu?????\\\"\\ntext = re.sub(r\\\"(.)\\\\1+\\\", r\\\"\\\\1\\\", st)\\ntext\";\n",
       "                var nbb_formatted_code = \"st = \\\"hhheeeLLLLooo hoooowww areee youuu?????\\\"\\ntext = re.sub(r\\\"(.)\\\\1+\\\", r\\\"\\\\1\\\", st)\\ntext\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st = \"hhheeeLLLLooo hoooowww areee youuu?????\"\n",
    "text = re.sub(r\"(.)\\1+\", r\"\\1\", st)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "monthly-rapid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:44:48.622525Z",
     "start_time": "2021-03-28T20:44:48.518501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 100;\n",
       "                var nbb_unformatted_code = \"from spellchecker import SpellChecker\\n\\ntext = nlp(text)\\nspell = SpellChecker()\\n\\n# find those words that may be misspelled\\nmisspelled = spell.unknown([token.text for token in text])\\n\\nfor word in misspelled:\\n    # Get the one `most likely` answer\\n    print(spell.correction(word))\\n\\n    # Get a list of `likely` options\\n    print(spell.candidates(word))\";\n",
       "                var nbb_formatted_code = \"from spellchecker import SpellChecker\\n\\ntext = nlp(text)\\nspell = SpellChecker()\\n\\n# find those words that may be misspelled\\nmisspelled = spell.unknown([token.text for token in text])\\n\\nfor word in misspelled:\\n    # Get the one `most likely` answer\\n    print(spell.correction(word))\\n\\n    # Get a list of `likely` options\\n    print(spell.candidates(word))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "text = nlp(text)\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown([token.text for token in text])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-marriage",
   "metadata": {},
   "source": [
    "It didn't find any mispelled (even if there was \"helo\"). Try another spell checker:\n",
    "\n",
    "https://github.com/fsondej/autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "terminal-occupation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:43:37.953727Z",
     "start_time": "2021-03-28T20:43:37.889573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hero how are you?'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 95;\n",
       "                var nbb_unformatted_code = \"from autocorrect import Speller\\n\\nspell = Speller()\\n\\nspell(text.text)\";\n",
       "                var nbb_formatted_code = \"from autocorrect import Speller\\n\\nspell = Speller()\\n\\nspell(text.text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "\n",
    "spell(text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-language",
   "metadata": {},
   "source": [
    "As you can see, it's not always working properly! However, overall it should improve your text.\n",
    "\n",
    "If you want to create a separate lemmatizer instead of having it in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "false-portrait",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:50:55.492317Z",
     "start_time": "2021-03-28T20:50:55.486168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['study']\n",
      "['studying']\n",
      "['studying']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 109;\n",
       "                var nbb_unformatted_code = \"from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\\n\\nlemmatizer = nlp.vocab.morphology.lemmatizer\\nprint(lemmatizer(\\\"studying\\\", VERB))\\nprint(lemmatizer(\\\"studying\\\", NOUN))\\nprint(lemmatizer(\\\"studying\\\", ADJ))\";\n",
       "                var nbb_formatted_code = \"from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\\n\\nlemmatizer = nlp.vocab.morphology.lemmatizer\\nprint(lemmatizer(\\\"studying\\\", VERB))\\nprint(lemmatizer(\\\"studying\\\", NOUN))\\nprint(lemmatizer(\\\"studying\\\", ADJ))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\n",
    "\n",
    "lemmatizer = nlp.vocab.morphology.lemmatizer\n",
    "print(lemmatizer(\"studying\", VERB))\n",
    "print(lemmatizer(\"studying\", NOUN))\n",
    "print(lemmatizer(\"studying\", ADJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "civil-sterling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:52:21.406926Z",
     "start_time": "2021-03-28T20:52:21.398539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lemma_lookup', 'lemma_rules', 'lemma_index', 'lemma_exc', 'lexeme_norm']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 117;\n",
       "                var nbb_unformatted_code = \"nlp.vocab.lookups.tables\";\n",
       "                var nbb_formatted_code = \"nlp.vocab.lookups.tables\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.vocab.lookups.tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-header",
   "metadata": {},
   "source": [
    "spaCy has no built-in stemming! However, Lemmatization is enough for most of the tasks. As alternative, you can use [NLTK library](https://www.nltk.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-chart",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "A named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title. spaCy can recognize various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn’t always work perfectly and might need some tuning later, depending on your use case.\n",
    "\n",
    "Named entities are available as the ents property of a Doc.\n",
    "\n",
    "\n",
    "Example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "pacific-generation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:04:34.612659Z",
     "start_time": "2021-03-29T06:04:34.586397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 129;\n",
       "                var nbb_unformatted_code = \"doc = nlp(\\\"Antonio works at Strive School.\\\")\";\n",
       "                var nbb_formatted_code = \"doc = nlp(\\\"Antonio works at Strive School.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Antonio works at Strive School.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "prescription-swimming",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:04:49.092105Z",
     "start_time": "2021-03-29T06:04:49.075027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Antonio works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Strive School\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 131;\n",
       "                var nbb_unformatted_code = \"from spacy import displacy\\n\\ndisplacy.render(doc, style=\\\"ent\\\")\";\n",
       "                var nbb_formatted_code = \"from spacy import displacy\\n\\ndisplacy.render(doc, style=\\\"ent\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "substantial-bookmark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:06:02.488436Z",
     "start_time": "2021-03-29T06:06:02.459044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 136;\n",
       "                var nbb_unformatted_code = \"doc = nlp(\\\"Rome is a big city.\\\")\";\n",
       "                var nbb_formatted_code = \"doc = nlp(\\\"Rome is a big city.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Rome is a big city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "organized-reservoir",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:06:05.912053Z",
     "start_time": "2021-03-29T06:06:05.901532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rome\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a big city.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 137;\n",
       "                var nbb_unformatted_code = \"displacy.render(doc, style=\\\"ent\\\")\";\n",
       "                var nbb_formatted_code = \"displacy.render(doc, style=\\\"ent\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-gospel",
   "metadata": {},
   "source": [
    "ORG stands for organization, GPE stands for Geopolitical Entity. Some other tags are:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
