{"cells":[{"cell_type":"markdown","source":"<!--NAVIGATION-->\n\n<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/classic-datasets/Iris.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>","metadata":{"cell_id":"00000-93c3e4d3-99dd-4169-86f8-a6c35cddb92e","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# Guided ML With The Iris Dataset\n\n| Learning type | Activity type | Objective |\n| - | - | - |\n| Supervised | Multiclass classification | Identify a flower's class |\n\nContents:\n1. Loading the data\n2. Setting up supervised learning problem (selecting features)\n3. Creating a first model\n    - Creating train and test datasets\n    - Normalizing train and test\n    - Fitting and predicting\n4. Evaluate the frist model predictions\n5. Crossvalidation of the model\n6. Creating an end to end ML pipeline\n    - Train/Test Split\n    - Normalize\n    - Crossvalidations\n    - Model\n    - fitting and predicting","metadata":{"cell_id":"00001-2bf654ea-8807-45e2-b83f-a343cf45fbfc","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Instructions with NBGrader removed\n\nComplete the cells beginning with `# YOUR CODE HERE` and run the subsequent cells to check your code.","metadata":{"cell_id":"00002-6b23ee9b-5eda-4d45-87f9-e82eba0d4811","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## About the dataset\n\n[Iris](https://archive.ics.uci.edu/ml/datasets/iris) is a well-known multiclass dataset. It contains 3 classes of flowers with 50 examples each. There are a total of 4 features for each flower.\n\n![](./classic-datasets/images/Iris-versicolor-21_1.jpg)","metadata":{"cell_id":"00003-a664f16d-e66f-4f81-a40d-c9d7bbdb5269","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Package setups\n\n1. Run the following two cells to initalize the required libraries. ","metadata":{"cell_id":"00004-3566b1f2-30d8-4a7f-bf09-1c793b415059","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00005-dc5a4a11-47ea-49c7-bd71-5a74b58f913a","deepnote_to_be_reexecuted":false,"source_hash":"1e64b7fc","execution_millis":3,"execution_start":1611079389642,"deepnote_cell_type":"code"},"source":"#to debug package errors\nimport sys\nsys.path\nsys.executable","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"'/usr/local/bin/python'"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"00006-63202e64-c7f2-4605-a6db-ed9ba3afe35e","deepnote_to_be_reexecuted":false,"source_hash":"131b2e38","execution_millis":1038,"execution_start":1611170910993,"deepnote_cell_type":"code"},"source":"# Import needed packages\n# You may add or remove packages should you need them\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.pipeline import make_pipeline\n\n# Set random seed\nnp.random.seed(0)\n\n# Display plots inline and change plot resolution to retina\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n# Set Seaborn aesthetic parameters to defaults\nsns.set()","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00007-62a761e6-72d9-48bb-8fd1-9bb746896cd1","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Loading the data\n\n1. Load the iris dataset using ```datasets.load_iris()```\n2. Investigate the data structure with ```.keys()```\n3. Construct a dataframe from the dataset\n4. Create a 'target' and a 'class' column that contains the target names and values\n5. Display a random sample of the dataframe ","metadata":{"cell_id":"00008-1317832f-8db6-4548-b47c-6729c52a1a59","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00009-0b219aac-3984-4b08-ace5-2971e67c57b4","deepnote_to_be_reexecuted":false,"source_hash":"4c7c939c","execution_millis":3,"execution_start":1611170922781,"deepnote_cell_type":"code"},"source":"iris = datasets.load_iris()\niris.keys()\n","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"00010-aea8d54e-b8f0-4ce8-8024-78aa7d24f79f","deepnote_to_be_reexecuted":false,"source_hash":"d9d95b9f","execution_millis":28,"execution_start":1611170926236,"deepnote_cell_type":"code"},"source":"#your code here\ndf1 = pd.DataFrame(iris.data,columns=['sepal length','sepal width','petal length','petal width'])\ndf2 = pd.DataFrame(iris.target,columns=[\"target\"])\ndf2['class'] = df2.replace({0:iris.target_names[0],1:iris.target_names[1],2:iris.target_names[2]})\ndf = df1.join(df2)\ndf.sample(20)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":20,"column_count":6,"columns":[{"name":"sepal length","dtype":"float64","stats":{"unique_count":14,"nan_count":0,"min":4.8,"max":7.3,"histogram":[{"bin_start":4.8,"bin_end":5.05,"count":4},{"bin_start":5.05,"bin_end":5.3,"count":0},{"bin_start":5.3,"bin_end":5.55,"count":3},{"bin_start":5.55,"bin_end":5.8,"count":0},{"bin_start":5.8,"bin_end":6.05,"count":3},{"bin_start":6.05,"bin_end":6.3,"count":4},{"bin_start":6.3,"bin_end":6.55,"count":3},{"bin_start":6.55,"bin_end":6.8,"count":1},{"bin_start":6.8,"bin_end":7.05,"count":1},{"bin_start":7.05,"bin_end":7.3,"count":1}]}},{"name":"sepal width","dtype":"float64","stats":{"unique_count":13,"nan_count":0,"min":2.2,"max":4.2,"histogram":[{"bin_start":2.2,"bin_end":2.4000000000000004,"count":1},{"bin_start":2.4000000000000004,"bin_end":2.6,"count":0},{"bin_start":2.6,"bin_end":2.8000000000000003,"count":7},{"bin_start":2.8000000000000003,"bin_end":3,"count":3},{"bin_start":3,"bin_end":3.2,"count":2},{"bin_start":3.2,"bin_end":3.4000000000000004,"count":3},{"bin_start":3.4000000000000004,"bin_end":3.6000000000000005,"count":2},{"bin_start":3.6000000000000005,"bin_end":3.8000000000000003,"count":0},{"bin_start":3.8000000000000003,"bin_end":4,"count":1},{"bin_start":4,"bin_end":4.2,"count":1}]}},{"name":"petal length","dtype":"float64","stats":{"unique_count":13,"nan_count":0,"min":1.3,"max":6.3,"histogram":[{"bin_start":1.3,"bin_end":1.8,"count":6},{"bin_start":1.8,"bin_end":2.3,"count":0},{"bin_start":2.3,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.3,"count":0},{"bin_start":3.3,"bin_end":3.8,"count":0},{"bin_start":3.8,"bin_end":4.3,"count":2},{"bin_start":4.3,"bin_end":4.8,"count":7},{"bin_start":4.8,"bin_end":5.3,"count":2},{"bin_start":5.3,"bin_end":5.8,"count":1},{"bin_start":5.8,"bin_end":6.3,"count":2}]}},{"name":"petal width","dtype":"float64","stats":{"unique_count":12,"nan_count":0,"min":0.1,"max":2.5,"histogram":[{"bin_start":0.1,"bin_end":0.33999999999999997,"count":5},{"bin_start":0.33999999999999997,"bin_end":0.58,"count":1},{"bin_start":0.58,"bin_end":0.82,"count":0},{"bin_start":0.82,"bin_end":1.06,"count":1},{"bin_start":1.06,"bin_end":1.3,"count":2},{"bin_start":1.3,"bin_end":1.54,"count":8},{"bin_start":1.54,"bin_end":1.78,"count":0},{"bin_start":1.78,"bin_end":2.02,"count":1},{"bin_start":2.02,"bin_end":2.2600000000000002,"count":0},{"bin_start":2.2600000000000002,"bin_end":2.5,"count":2}]}},{"name":"target","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":0,"max":2,"histogram":[{"bin_start":0,"bin_end":0.2,"count":6},{"bin_start":0.2,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.2000000000000002,"count":10},{"bin_start":1.2000000000000002,"bin_end":1.4000000000000001,"count":0},{"bin_start":1.4000000000000001,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.8,"count":0},{"bin_start":1.8,"bin_end":2,"count":4}]}},{"name":"class","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"versicolor","count":10},{"name":"setosa","count":6},{"name":"virginica","count":4}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"sepal length":5.8,"sepal width":2.8,"petal length":5.1,"petal width":2.4,"target":2,"class":"virginica","_deepnote_index_column":114},{"sepal length":6,"sepal width":2.2,"petal length":4,"petal width":1,"target":1,"class":"versicolor","_deepnote_index_column":62},{"sepal length":5.5,"sepal width":4.2,"petal length":1.4,"petal width":0.2,"target":0,"class":"setosa","_deepnote_index_column":33},{"sepal length":7.3,"sepal width":2.9,"petal length":6.3,"petal width":1.8,"target":2,"class":"virginica","_deepnote_index_column":107},{"sepal length":5,"sepal width":3.4,"petal length":1.5,"petal width":0.2,"target":0,"class":"setosa","_deepnote_index_column":7},{"sepal length":6.3,"sepal width":3.3,"petal length":6,"petal width":2.5,"target":2,"class":"virginica","_deepnote_index_column":100},{"sepal length":5,"sepal width":3.5,"petal length":1.3,"petal width":0.3,"target":0,"class":"setosa","_deepnote_index_column":40},{"sepal length":6.7,"sepal width":3.1,"petal length":4.7,"petal width":1.5,"target":1,"class":"versicolor","_deepnote_index_column":86},{"sepal length":6.8,"sepal width":2.8,"petal length":4.8,"petal width":1.4,"target":1,"class":"versicolor","_deepnote_index_column":76},{"sepal length":6.1,"sepal width":2.8,"petal length":4,"petal width":1.3,"target":1,"class":"versicolor","_deepnote_index_column":71},{"sepal length":6.1,"sepal width":2.6,"petal length":5.6,"petal width":1.4,"target":2,"class":"virginica","_deepnote_index_column":134},{"sepal length":6.4,"sepal width":3.2,"petal length":4.5,"petal width":1.5,"target":1,"class":"versicolor","_deepnote_index_column":51},{"sepal length":6.1,"sepal width":2.8,"petal length":4.7,"petal width":1.2,"target":1,"class":"versicolor","_deepnote_index_column":73},{"sepal length":6.5,"sepal width":2.8,"petal length":4.6,"petal width":1.5,"target":1,"class":"versicolor","_deepnote_index_column":54},{"sepal length":6.1,"sepal width":2.9,"petal length":4.7,"petal width":1.4,"target":1,"class":"versicolor","_deepnote_index_column":63},{"sepal length":4.9,"sepal width":3.6,"petal length":1.4,"petal width":0.1,"target":0,"class":"setosa","_deepnote_index_column":37},{"sepal length":6,"sepal width":2.9,"petal length":4.5,"petal width":1.5,"target":1,"class":"versicolor","_deepnote_index_column":78},{"sepal length":5.5,"sepal width":2.6,"petal length":4.4,"petal width":1.2,"target":1,"class":"versicolor","_deepnote_index_column":90},{"sepal length":4.8,"sepal width":3,"petal length":1.4,"petal width":0.3,"target":0,"class":"setosa","_deepnote_index_column":45},{"sepal length":5.4,"sepal width":3.9,"petal length":1.3,"petal width":0.4,"target":0,"class":"setosa","_deepnote_index_column":16}],"rows_bottom":null},"text/plain":"     sepal length  sepal width  petal length  petal width  target       class\n114           5.8          2.8           5.1          2.4       2   virginica\n62            6.0          2.2           4.0          1.0       1  versicolor\n33            5.5          4.2           1.4          0.2       0      setosa\n107           7.3          2.9           6.3          1.8       2   virginica\n7             5.0          3.4           1.5          0.2       0      setosa\n100           6.3          3.3           6.0          2.5       2   virginica\n40            5.0          3.5           1.3          0.3       0      setosa\n86            6.7          3.1           4.7          1.5       1  versicolor\n76            6.8          2.8           4.8          1.4       1  versicolor\n71            6.1          2.8           4.0          1.3       1  versicolor\n134           6.1          2.6           5.6          1.4       2   virginica\n51            6.4          3.2           4.5          1.5       1  versicolor\n73            6.1          2.8           4.7          1.2       1  versicolor\n54            6.5          2.8           4.6          1.5       1  versicolor\n63            6.1          2.9           4.7          1.4       1  versicolor\n37            4.9          3.6           1.4          0.1       0      setosa\n78            6.0          2.9           4.5          1.5       1  versicolor\n90            5.5          2.6           4.4          1.2       1  versicolor\n45            4.8          3.0           1.4          0.3       0      setosa\n16            5.4          3.9           1.3          0.4       0      setosa","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length</th>\n      <th>sepal width</th>\n      <th>petal length</th>\n      <th>petal width</th>\n      <th>target</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>114</th>\n      <td>5.8</td>\n      <td>2.8</td>\n      <td>5.1</td>\n      <td>2.4</td>\n      <td>2</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>6.0</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>5.5</td>\n      <td>4.2</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>7.3</td>\n      <td>2.9</td>\n      <td>6.3</td>\n      <td>1.8</td>\n      <td>2</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>6.3</td>\n      <td>3.3</td>\n      <td>6.0</td>\n      <td>2.5</td>\n      <td>2</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>5.0</td>\n      <td>3.5</td>\n      <td>1.3</td>\n      <td>0.3</td>\n      <td>0</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>6.7</td>\n      <td>3.1</td>\n      <td>4.7</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>6.8</td>\n      <td>2.8</td>\n      <td>4.8</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>6.1</td>\n      <td>2.8</td>\n      <td>4.0</td>\n      <td>1.3</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>6.1</td>\n      <td>2.6</td>\n      <td>5.6</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>6.4</td>\n      <td>3.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>6.1</td>\n      <td>2.8</td>\n      <td>4.7</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>6.5</td>\n      <td>2.8</td>\n      <td>4.6</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>6.1</td>\n      <td>2.9</td>\n      <td>4.7</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>4.9</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.1</td>\n      <td>0</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>6.0</td>\n      <td>2.9</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>5.5</td>\n      <td>2.6</td>\n      <td>4.4</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>4.8</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.3</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Question\nFind the X and y values we're looking for. Notice that y is categorical and thus, we could **one-hot encode it** if we are looking at **class** or we can just pick **target**. In order to one hot encode we have  to re-shape `y` it using the **.get_dummies** function. \n\n#### For the purpose of this exercise, do not use hot encoding, go only for target but think about if you have to drop it somewhere or not...","metadata":{"cell_id":"00011-51d7f856-3bda-412f-9b00-a0a20d732d50","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00012-71d8895e-27c6-4daf-869d-ebba41783d98","deepnote_to_be_reexecuted":false,"source_hash":"3865bd3d","execution_millis":43,"execution_start":1611170933597,"deepnote_cell_type":"code"},"source":"# YOUR CODE HERE\nX = df.drop(['class','target'], axis = 1)\ny = df['target']\nX\n","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":150,"column_count":4,"columns":[{"name":"sepal length","dtype":"float64","stats":{"unique_count":35,"nan_count":0,"min":4.3,"max":7.9,"histogram":[{"bin_start":4.3,"bin_end":4.66,"count":9},{"bin_start":4.66,"bin_end":5.02,"count":23},{"bin_start":5.02,"bin_end":5.38,"count":14},{"bin_start":5.38,"bin_end":5.74,"count":27},{"bin_start":5.74,"bin_end":6.1,"count":16},{"bin_start":6.1,"bin_end":6.46,"count":26},{"bin_start":6.46,"bin_end":6.82,"count":18},{"bin_start":6.82,"bin_end":7.18,"count":6},{"bin_start":7.18,"bin_end":7.54,"count":5},{"bin_start":7.54,"bin_end":7.9,"count":6}]}},{"name":"sepal width","dtype":"float64","stats":{"unique_count":23,"nan_count":0,"min":2,"max":4.4,"histogram":[{"bin_start":2,"bin_end":2.24,"count":4},{"bin_start":2.24,"bin_end":2.48,"count":7},{"bin_start":2.48,"bin_end":2.72,"count":22},{"bin_start":2.72,"bin_end":2.96,"count":24},{"bin_start":2.96,"bin_end":3.2,"count":37},{"bin_start":3.2,"bin_end":3.4400000000000004,"count":31},{"bin_start":3.4400000000000004,"bin_end":3.6800000000000006,"count":10},{"bin_start":3.6800000000000006,"bin_end":3.9200000000000004,"count":11},{"bin_start":3.9200000000000004,"bin_end":4.16,"count":2},{"bin_start":4.16,"bin_end":4.4,"count":2}]}},{"name":"petal length","dtype":"float64","stats":{"unique_count":43,"nan_count":0,"min":1,"max":6.9,"histogram":[{"bin_start":1,"bin_end":1.59,"count":37},{"bin_start":1.59,"bin_end":2.18,"count":13},{"bin_start":2.18,"bin_end":2.7700000000000005,"count":0},{"bin_start":2.7700000000000005,"bin_end":3.3600000000000003,"count":3},{"bin_start":3.3600000000000003,"bin_end":3.95,"count":8},{"bin_start":3.95,"bin_end":4.540000000000001,"count":26},{"bin_start":4.540000000000001,"bin_end":5.130000000000001,"count":29},{"bin_start":5.130000000000001,"bin_end":5.720000000000001,"count":18},{"bin_start":5.720000000000001,"bin_end":6.3100000000000005,"count":11},{"bin_start":6.3100000000000005,"bin_end":6.9,"count":5}]}},{"name":"petal width","dtype":"float64","stats":{"unique_count":22,"nan_count":0,"min":0.1,"max":2.5,"histogram":[{"bin_start":0.1,"bin_end":0.33999999999999997,"count":41},{"bin_start":0.33999999999999997,"bin_end":0.58,"count":8},{"bin_start":0.58,"bin_end":0.82,"count":1},{"bin_start":0.82,"bin_end":1.06,"count":7},{"bin_start":1.06,"bin_end":1.3,"count":8},{"bin_start":1.3,"bin_end":1.54,"count":33},{"bin_start":1.54,"bin_end":1.78,"count":6},{"bin_start":1.78,"bin_end":2.02,"count":23},{"bin_start":2.02,"bin_end":2.2600000000000002,"count":9},{"bin_start":2.2600000000000002,"bin_end":2.5,"count":14}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"sepal length":5.1,"sepal width":3.5,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":0},{"sepal length":4.9,"sepal width":3,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":1},{"sepal length":4.7,"sepal width":3.2,"petal length":1.3,"petal width":0.2,"_deepnote_index_column":2},{"sepal length":4.6,"sepal width":3.1,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":3},{"sepal length":5,"sepal width":3.6,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":4},{"sepal length":5.4,"sepal width":3.9,"petal length":1.7,"petal width":0.4,"_deepnote_index_column":5},{"sepal length":4.6,"sepal width":3.4,"petal length":1.4,"petal width":0.3,"_deepnote_index_column":6},{"sepal length":5,"sepal width":3.4,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":7},{"sepal length":4.4,"sepal width":2.9,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":8},{"sepal length":4.9,"sepal width":3.1,"petal length":1.5,"petal width":0.1,"_deepnote_index_column":9},{"sepal length":5.4,"sepal width":3.7,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":10},{"sepal length":4.8,"sepal width":3.4,"petal length":1.6,"petal width":0.2,"_deepnote_index_column":11},{"sepal length":4.8,"sepal width":3,"petal length":1.4,"petal width":0.1,"_deepnote_index_column":12},{"sepal length":4.3,"sepal width":3,"petal length":1.1,"petal width":0.1,"_deepnote_index_column":13},{"sepal length":5.8,"sepal width":4,"petal length":1.2,"petal width":0.2,"_deepnote_index_column":14},{"sepal length":5.7,"sepal width":4.4,"petal length":1.5,"petal width":0.4,"_deepnote_index_column":15},{"sepal length":5.4,"sepal width":3.9,"petal length":1.3,"petal width":0.4,"_deepnote_index_column":16},{"sepal length":5.1,"sepal width":3.5,"petal length":1.4,"petal width":0.3,"_deepnote_index_column":17},{"sepal length":5.7,"sepal width":3.8,"petal length":1.7,"petal width":0.3,"_deepnote_index_column":18},{"sepal length":5.1,"sepal width":3.8,"petal length":1.5,"petal width":0.3,"_deepnote_index_column":19},{"sepal length":5.4,"sepal width":3.4,"petal length":1.7,"petal width":0.2,"_deepnote_index_column":20},{"sepal length":5.1,"sepal width":3.7,"petal length":1.5,"petal width":0.4,"_deepnote_index_column":21},{"sepal length":4.6,"sepal width":3.6,"petal length":1,"petal width":0.2,"_deepnote_index_column":22},{"sepal length":5.1,"sepal width":3.3,"petal length":1.7,"petal width":0.5,"_deepnote_index_column":23},{"sepal length":4.8,"sepal width":3.4,"petal length":1.9,"petal width":0.2,"_deepnote_index_column":24},{"sepal length":5,"sepal width":3,"petal length":1.6,"petal width":0.2,"_deepnote_index_column":25},{"sepal length":5,"sepal width":3.4,"petal length":1.6,"petal width":0.4,"_deepnote_index_column":26},{"sepal length":5.2,"sepal width":3.5,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":27},{"sepal length":5.2,"sepal width":3.4,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":28},{"sepal length":4.7,"sepal width":3.2,"petal length":1.6,"petal width":0.2,"_deepnote_index_column":29},{"sepal length":4.8,"sepal width":3.1,"petal length":1.6,"petal width":0.2,"_deepnote_index_column":30},{"sepal length":5.4,"sepal width":3.4,"petal length":1.5,"petal width":0.4,"_deepnote_index_column":31},{"sepal length":5.2,"sepal width":4.1,"petal length":1.5,"petal width":0.1,"_deepnote_index_column":32},{"sepal length":5.5,"sepal width":4.2,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":33},{"sepal length":4.9,"sepal width":3.1,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":34},{"sepal length":5,"sepal width":3.2,"petal length":1.2,"petal width":0.2,"_deepnote_index_column":35},{"sepal length":5.5,"sepal width":3.5,"petal length":1.3,"petal width":0.2,"_deepnote_index_column":36},{"sepal length":4.9,"sepal width":3.6,"petal length":1.4,"petal width":0.1,"_deepnote_index_column":37},{"sepal length":4.4,"sepal width":3,"petal length":1.3,"petal width":0.2,"_deepnote_index_column":38},{"sepal length":5.1,"sepal width":3.4,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":39},{"sepal length":5,"sepal width":3.5,"petal length":1.3,"petal width":0.3,"_deepnote_index_column":40},{"sepal length":4.5,"sepal width":2.3,"petal length":1.3,"petal width":0.3,"_deepnote_index_column":41},{"sepal length":4.4,"sepal width":3.2,"petal length":1.3,"petal width":0.2,"_deepnote_index_column":42},{"sepal length":5,"sepal width":3.5,"petal length":1.6,"petal width":0.6,"_deepnote_index_column":43},{"sepal length":5.1,"sepal width":3.8,"petal length":1.9,"petal width":0.4,"_deepnote_index_column":44},{"sepal length":4.8,"sepal width":3,"petal length":1.4,"petal width":0.3,"_deepnote_index_column":45},{"sepal length":5.1,"sepal width":3.8,"petal length":1.6,"petal width":0.2,"_deepnote_index_column":46},{"sepal length":4.6,"sepal width":3.2,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":47},{"sepal length":5.3,"sepal width":3.7,"petal length":1.5,"petal width":0.2,"_deepnote_index_column":48},{"sepal length":5,"sepal width":3.3,"petal length":1.4,"petal width":0.2,"_deepnote_index_column":49},{"sepal length":7,"sepal width":3.2,"petal length":4.7,"petal width":1.4,"_deepnote_index_column":50},{"sepal length":6.4,"sepal width":3.2,"petal length":4.5,"petal width":1.5,"_deepnote_index_column":51},{"sepal length":6.9,"sepal width":3.1,"petal length":4.9,"petal width":1.5,"_deepnote_index_column":52},{"sepal length":5.5,"sepal width":2.3,"petal length":4,"petal width":1.3,"_deepnote_index_column":53},{"sepal length":6.5,"sepal width":2.8,"petal length":4.6,"petal width":1.5,"_deepnote_index_column":54},{"sepal length":5.7,"sepal width":2.8,"petal length":4.5,"petal width":1.3,"_deepnote_index_column":55},{"sepal length":6.3,"sepal width":3.3,"petal length":4.7,"petal width":1.6,"_deepnote_index_column":56},{"sepal length":4.9,"sepal width":2.4,"petal length":3.3,"petal width":1,"_deepnote_index_column":57},{"sepal length":6.6,"sepal width":2.9,"petal length":4.6,"petal width":1.3,"_deepnote_index_column":58},{"sepal length":5.2,"sepal width":2.7,"petal length":3.9,"petal width":1.4,"_deepnote_index_column":59},{"sepal length":5,"sepal width":2,"petal length":3.5,"petal width":1,"_deepnote_index_column":60},{"sepal length":5.9,"sepal width":3,"petal length":4.2,"petal width":1.5,"_deepnote_index_column":61},{"sepal length":6,"sepal width":2.2,"petal length":4,"petal width":1,"_deepnote_index_column":62},{"sepal length":6.1,"sepal width":2.9,"petal length":4.7,"petal width":1.4,"_deepnote_index_column":63},{"sepal length":5.6,"sepal width":2.9,"petal length":3.6,"petal width":1.3,"_deepnote_index_column":64},{"sepal length":6.7,"sepal width":3.1,"petal length":4.4,"petal width":1.4,"_deepnote_index_column":65},{"sepal length":5.6,"sepal width":3,"petal length":4.5,"petal width":1.5,"_deepnote_index_column":66},{"sepal length":5.8,"sepal width":2.7,"petal length":4.1,"petal width":1,"_deepnote_index_column":67},{"sepal length":6.2,"sepal width":2.2,"petal length":4.5,"petal width":1.5,"_deepnote_index_column":68},{"sepal length":5.6,"sepal width":2.5,"petal length":3.9,"petal width":1.1,"_deepnote_index_column":69},{"sepal length":5.9,"sepal width":3.2,"petal length":4.8,"petal width":1.8,"_deepnote_index_column":70},{"sepal length":6.1,"sepal width":2.8,"petal length":4,"petal width":1.3,"_deepnote_index_column":71},{"sepal length":6.3,"sepal width":2.5,"petal length":4.9,"petal width":1.5,"_deepnote_index_column":72},{"sepal length":6.1,"sepal width":2.8,"petal length":4.7,"petal width":1.2,"_deepnote_index_column":73},{"sepal length":6.4,"sepal width":2.9,"petal length":4.3,"petal width":1.3,"_deepnote_index_column":74},{"sepal length":6.6,"sepal width":3,"petal length":4.4,"petal width":1.4,"_deepnote_index_column":75},{"sepal length":6.8,"sepal width":2.8,"petal length":4.8,"petal width":1.4,"_deepnote_index_column":76},{"sepal length":6.7,"sepal width":3,"petal length":5,"petal width":1.7,"_deepnote_index_column":77},{"sepal length":6,"sepal width":2.9,"petal length":4.5,"petal width":1.5,"_deepnote_index_column":78},{"sepal length":5.7,"sepal width":2.6,"petal length":3.5,"petal width":1,"_deepnote_index_column":79},{"sepal length":5.5,"sepal width":2.4,"petal length":3.8,"petal width":1.1,"_deepnote_index_column":80},{"sepal length":5.5,"sepal width":2.4,"petal length":3.7,"petal width":1,"_deepnote_index_column":81},{"sepal length":5.8,"sepal width":2.7,"petal length":3.9,"petal width":1.2,"_deepnote_index_column":82},{"sepal length":6,"sepal width":2.7,"petal length":5.1,"petal width":1.6,"_deepnote_index_column":83},{"sepal length":5.4,"sepal width":3,"petal length":4.5,"petal width":1.5,"_deepnote_index_column":84},{"sepal length":6,"sepal width":3.4,"petal length":4.5,"petal width":1.6,"_deepnote_index_column":85},{"sepal length":6.7,"sepal width":3.1,"petal length":4.7,"petal width":1.5,"_deepnote_index_column":86},{"sepal length":6.3,"sepal width":2.3,"petal length":4.4,"petal width":1.3,"_deepnote_index_column":87},{"sepal length":5.6,"sepal width":3,"petal length":4.1,"petal width":1.3,"_deepnote_index_column":88},{"sepal length":5.5,"sepal width":2.5,"petal length":4,"petal width":1.3,"_deepnote_index_column":89},{"sepal length":5.5,"sepal width":2.6,"petal length":4.4,"petal width":1.2,"_deepnote_index_column":90},{"sepal length":6.1,"sepal width":3,"petal length":4.6,"petal width":1.4,"_deepnote_index_column":91},{"sepal length":5.8,"sepal width":2.6,"petal length":4,"petal width":1.2,"_deepnote_index_column":92},{"sepal length":5,"sepal width":2.3,"petal length":3.3,"petal width":1,"_deepnote_index_column":93},{"sepal length":5.6,"sepal width":2.7,"petal length":4.2,"petal width":1.3,"_deepnote_index_column":94},{"sepal length":5.7,"sepal width":3,"petal length":4.2,"petal width":1.2,"_deepnote_index_column":95},{"sepal length":5.7,"sepal width":2.9,"petal length":4.2,"petal width":1.3,"_deepnote_index_column":96},{"sepal length":6.2,"sepal width":2.9,"petal length":4.3,"petal width":1.3,"_deepnote_index_column":97},{"sepal length":5.1,"sepal width":2.5,"petal length":3,"petal width":1.1,"_deepnote_index_column":98},{"sepal length":5.7,"sepal width":2.8,"petal length":4.1,"petal width":1.3,"_deepnote_index_column":99},{"sepal length":6.3,"sepal width":3.3,"petal length":6,"petal width":2.5,"_deepnote_index_column":100},{"sepal length":5.8,"sepal width":2.7,"petal length":5.1,"petal width":1.9,"_deepnote_index_column":101},{"sepal length":7.1,"sepal width":3,"petal length":5.9,"petal width":2.1,"_deepnote_index_column":102},{"sepal length":6.3,"sepal width":2.9,"petal length":5.6,"petal width":1.8,"_deepnote_index_column":103},{"sepal length":6.5,"sepal width":3,"petal length":5.8,"petal width":2.2,"_deepnote_index_column":104},{"sepal length":7.6,"sepal width":3,"petal length":6.6,"petal width":2.1,"_deepnote_index_column":105},{"sepal length":4.9,"sepal width":2.5,"petal length":4.5,"petal width":1.7,"_deepnote_index_column":106},{"sepal length":7.3,"sepal width":2.9,"petal length":6.3,"petal width":1.8,"_deepnote_index_column":107},{"sepal length":6.7,"sepal width":2.5,"petal length":5.8,"petal width":1.8,"_deepnote_index_column":108},{"sepal length":7.2,"sepal width":3.6,"petal length":6.1,"petal width":2.5,"_deepnote_index_column":109},{"sepal length":6.5,"sepal width":3.2,"petal length":5.1,"petal width":2,"_deepnote_index_column":110},{"sepal length":6.4,"sepal width":2.7,"petal length":5.3,"petal width":1.9,"_deepnote_index_column":111},{"sepal length":6.8,"sepal width":3,"petal length":5.5,"petal width":2.1,"_deepnote_index_column":112},{"sepal length":5.7,"sepal width":2.5,"petal length":5,"petal width":2,"_deepnote_index_column":113},{"sepal length":5.8,"sepal width":2.8,"petal length":5.1,"petal width":2.4,"_deepnote_index_column":114},{"sepal length":6.4,"sepal width":3.2,"petal length":5.3,"petal width":2.3,"_deepnote_index_column":115},{"sepal length":6.5,"sepal width":3,"petal length":5.5,"petal width":1.8,"_deepnote_index_column":116},{"sepal length":7.7,"sepal width":3.8,"petal length":6.7,"petal width":2.2,"_deepnote_index_column":117},{"sepal length":7.7,"sepal width":2.6,"petal length":6.9,"petal width":2.3,"_deepnote_index_column":118},{"sepal length":6,"sepal width":2.2,"petal length":5,"petal width":1.5,"_deepnote_index_column":119},{"sepal length":6.9,"sepal width":3.2,"petal length":5.7,"petal width":2.3,"_deepnote_index_column":120},{"sepal length":5.6,"sepal width":2.8,"petal length":4.9,"petal width":2,"_deepnote_index_column":121},{"sepal length":7.7,"sepal width":2.8,"petal length":6.7,"petal width":2,"_deepnote_index_column":122},{"sepal length":6.3,"sepal width":2.7,"petal length":4.9,"petal width":1.8,"_deepnote_index_column":123},{"sepal length":6.7,"sepal width":3.3,"petal length":5.7,"petal width":2.1,"_deepnote_index_column":124},{"sepal length":7.2,"sepal width":3.2,"petal length":6,"petal width":1.8,"_deepnote_index_column":125},{"sepal length":6.2,"sepal width":2.8,"petal length":4.8,"petal width":1.8,"_deepnote_index_column":126},{"sepal length":6.1,"sepal width":3,"petal length":4.9,"petal width":1.8,"_deepnote_index_column":127},{"sepal length":6.4,"sepal width":2.8,"petal length":5.6,"petal width":2.1,"_deepnote_index_column":128},{"sepal length":7.2,"sepal width":3,"petal length":5.8,"petal width":1.6,"_deepnote_index_column":129},{"sepal length":7.4,"sepal width":2.8,"petal length":6.1,"petal width":1.9,"_deepnote_index_column":130},{"sepal length":7.9,"sepal width":3.8,"petal length":6.4,"petal width":2,"_deepnote_index_column":131},{"sepal length":6.4,"sepal width":2.8,"petal length":5.6,"petal width":2.2,"_deepnote_index_column":132},{"sepal length":6.3,"sepal width":2.8,"petal length":5.1,"petal width":1.5,"_deepnote_index_column":133},{"sepal length":6.1,"sepal width":2.6,"petal length":5.6,"petal width":1.4,"_deepnote_index_column":134},{"sepal length":7.7,"sepal width":3,"petal length":6.1,"petal width":2.3,"_deepnote_index_column":135},{"sepal length":6.3,"sepal width":3.4,"petal length":5.6,"petal width":2.4,"_deepnote_index_column":136},{"sepal length":6.4,"sepal width":3.1,"petal length":5.5,"petal width":1.8,"_deepnote_index_column":137},{"sepal length":6,"sepal width":3,"petal length":4.8,"petal width":1.8,"_deepnote_index_column":138},{"sepal length":6.9,"sepal width":3.1,"petal length":5.4,"petal width":2.1,"_deepnote_index_column":139},{"sepal length":6.7,"sepal width":3.1,"petal length":5.6,"petal width":2.4,"_deepnote_index_column":140},{"sepal length":6.9,"sepal width":3.1,"petal length":5.1,"petal width":2.3,"_deepnote_index_column":141},{"sepal length":5.8,"sepal width":2.7,"petal length":5.1,"petal width":1.9,"_deepnote_index_column":142},{"sepal length":6.8,"sepal width":3.2,"petal length":5.9,"petal width":2.3,"_deepnote_index_column":143},{"sepal length":6.7,"sepal width":3.3,"petal length":5.7,"petal width":2.5,"_deepnote_index_column":144},{"sepal length":6.7,"sepal width":3,"petal length":5.2,"petal width":2.3,"_deepnote_index_column":145},{"sepal length":6.3,"sepal width":2.5,"petal length":5,"petal width":1.9,"_deepnote_index_column":146},{"sepal length":6.5,"sepal width":3,"petal length":5.2,"petal width":2,"_deepnote_index_column":147},{"sepal length":6.2,"sepal width":3.4,"petal length":5.4,"petal width":2.3,"_deepnote_index_column":148},{"sepal length":5.9,"sepal width":3,"petal length":5.1,"petal width":1.8,"_deepnote_index_column":149}],"rows_bottom":null},"text/plain":"     sepal length  sepal width  petal length  petal width\n0             5.1          3.5           1.4          0.2\n1             4.9          3.0           1.4          0.2\n2             4.7          3.2           1.3          0.2\n3             4.6          3.1           1.5          0.2\n4             5.0          3.6           1.4          0.2\n..            ...          ...           ...          ...\n145           6.7          3.0           5.2          2.3\n146           6.3          2.5           5.0          1.9\n147           6.5          3.0           5.2          2.0\n148           6.2          3.4           5.4          2.3\n149           5.9          3.0           5.1          1.8\n\n[150 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length</th>\n      <th>sepal width</th>\n      <th>petal length</th>\n      <th>petal width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Step 2: Setting up supervised learning problem (selecting features)\n\nFeature selection is an essential step in improving a model's perfromance. In the first version of the model we will use the 'sepal length' and 'sepal width' as predicting features. Later we will see the effect of adding additional features.\n\n1. Assign the values of the 'target' to Y as a numpy array\n2. Assign the remaining feature values to X as a numpy array\n3. Check the shape of X and Y. Check the first few values.\n    - Can we confirm our X and Y are created correctly?","metadata":{"cell_id":"00013-e9ebb577-3bc2-42ed-a5be-8a6ca079d959","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00014-93f4ab17-8d4c-424a-ad2d-e722bd7bc000","deepnote_to_be_reexecuted":false,"source_hash":"a09ade1","execution_millis":0,"execution_start":1611170964532,"deepnote_cell_type":"code"},"source":"#your code here\nY = y.values\n#print(type(Y))\nprint(Y.shape)","execution_count":6,"outputs":[{"name":"stdout","text":"(150,)\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00015-eb9dfe63-2891-4901-9d09-ae5d5db040d6","deepnote_to_be_reexecuted":false,"source_hash":"c5a3ea7a","execution_millis":2,"execution_start":1611170967100,"deepnote_cell_type":"code"},"source":"#your code here\nX = df.iloc[:,1:3].values\n#print(type(X2))\nX.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(150, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Step 3: Creating the first model\n\nIn lecture we learned about creating a train and test datasets, normalizing, and fitting a model. In this step we will see how to build a simple version of this.\n\nWe have to be careful when constructing our train and test datasets. First, when we create train and test datasets we have to be careful that we always have the same datapoints in each set. Otherwise our results won't be reproduceable or we might introduce a bias into our model.\n\nWe also need to be attentive to when we normalize the data. What would be the effect of normalizing the data (i.e. with StandardScaler to a range between 0 - 1) before we create our train and test sets? Effectively we would use information in the test set to structure the values in the training set and vice versa. Therefore normalizing train and test independently is the preferred method.\n\n1. Create X_train, X_test, Y_train, Y_test using ```train_test_split()``` with an 80/20 train/test split. Look in the SKLearn documentation to understand how the function works.\n    - Inspect the first few rows of X_train.\n    - Run the cell a few times. Do the first few rows change?\n    - What option can we use in ```train_test_split()``` to stop this from happening?\n2. Normalize the train and test datasets with ```StandardScaler```\n    - We can fit the transform with ```.fit()``` and ```.transform()``` to apply it. Look in the documentation for an esample of how to do this.\n    - Does it make sense to normalize Y_train and Y_test?\n3. Initalize a ```LogisticRegression()``` model and use the ```.fit()``` method to initalize the first model.\n    - We will pass the X_train and Y_train variables to the ```.fit()``` method.\n    - Once the model is fit, use the ```.predict()``` with the X_test and save the output as predictions.","metadata":{"cell_id":"00016-8cf30205-cbea-45bc-8136-7cc8feb8c443","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00017-138a7d24-2ad8-4731-8de7-4cf48e98b3ae","deepnote_to_be_reexecuted":false,"source_hash":"597e25cc","execution_millis":1,"execution_start":1611170984159,"deepnote_cell_type":"code"},"source":"#split train and test data 80/20\n#your code here\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)\n","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00018-8f494a1a-a705-45e1-a783-6de4e2b0cecc","deepnote_to_be_reexecuted":false,"source_hash":"a01f384d","execution_millis":3,"execution_start":1611171025112,"deepnote_cell_type":"code"},"source":"#normalize the dataset\n#your code here\n\nscale = StandardScaler()\nX_train  = scale.fit_transform(X_train)\nX_test = scale.transform(X_test)\n","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00019-7754b694-9c9a-4d35-aba6-efa1f3c45374","deepnote_to_be_reexecuted":false,"source_hash":"da1ff29b","execution_millis":10,"execution_start":1611171030995,"deepnote_cell_type":"code"},"source":"#initalize and fit with Logistic Regression\n#your code here\nmodel = LogisticRegression()\nmodel.fit(X_train,Y_train)\npredictions = model.predict(X_test)\nprint(predictions)\n","execution_count":11,"outputs":[{"name":"stdout","text":"[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 1 0 0 1 1 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 4: Evaluate the frist model's predictions\n\nWe will learn more about how to evaluate the performance of a classifier in later lessons. For now we will use % accuracy as our metric. It is important to know that this metric only helps us understand the specific performance of our model and not, for example, where we can improve it, or where it already perfoms well.\n\n1. Use ```.score()``` to evaluate the performance of our first model.","metadata":{"cell_id":"00020-a994b67e-e126-4d61-8798-407b840f3c71","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00021-8436bfcb-bed5-4ef8-9bcc-845a551c570b","deepnote_to_be_reexecuted":false,"source_hash":"e5db4594","execution_millis":3,"execution_start":1611171036039,"deepnote_cell_type":"code"},"source":"#evaluating the performace of our first model\n#your code here\nmodel.score(X_test,Y_test)\n","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0.9666666666666667"},"metadata":{}}]},{"cell_type":"markdown","source":"## Step 5: Question your results. \nWhat accuracy did you achieve? Is it 70, 90%? Anything above 70% is a good fit for our first result. How do we know it is reproducible? **If we run the model again and our performance is 85%, which one is correct**? And what about improving our model? \n\n## However ...\nThere is one crucial mistake that has been made in the exercise above -even if we achieved great results-. Can you spot it? You can go back to the lecture slides for inspiration. ","metadata":{"cell_id":"00022-256eb718-3fa4-4ea9-b49f-c1dcd209124c","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"*Type your answer here...*","metadata":{"cell_id":"00023-c0a83bea-f8d0-4aa3-9f71-e332f3465380","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Optional:\nRepeat the cells you need to change in the exercise and run the classifier again. What is the new accuracy and why is this better?","metadata":{"cell_id":"00024-06be85e1-f52f-49d9-b776-a7a4fd8a08d6","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00025-55a94bdb-74ca-4dad-9948-444c799bd3be","deepnote_cell_type":"code"},"source":"#your code here","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"deepnote_notebook_id":"f4d7dbc2-9bb8-4601-8751-3490c867f191","deepnote_execution_queue":[]}}