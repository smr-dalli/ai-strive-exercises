{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "valid-consultation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:32:23.755820Z",
     "start_time": "2021-03-30T19:32:22.644310Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-mortgage",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "**Exercise 1.1**\n",
    "\n",
    "You are given the words \"playing\", \"played\", \"play\". Find the lemma using spaCy for all of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "english-plate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:34:20.464484Z",
     "start_time": "2021-03-30T19:34:20.425793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemma of the playing is play\n",
      "The lemma of the played is play\n",
      "The lemma of the playing is play\n"
     ]
    }
   ],
   "source": [
    "words = [\"playing\", \"played\", \"playing\"]\n",
    "\n",
    "lemmatizer = nlp.vocab.morphology.lemmatizer\n",
    "\n",
    "for word in words:\n",
    "    x = ''.join(lemmatizer.verb(word))\n",
    "    print(f'The lemma of the {word} is {x}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-commonwealth",
   "metadata": {},
   "source": [
    "**Exercise 1.2**\n",
    "\n",
    "Assign the spaCy lemmatizer to a variable instead of using the whole `nlp` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-champion",
   "metadata": {},
   "source": [
    "**Exercise 1.3**\n",
    "\n",
    "Find the verb, the noun and the adjective forms of the words: \"playing\", \"played\", \"surfing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elementary-blood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:41:42.605031Z",
     "start_time": "2021-03-30T19:41:42.595092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['play']\n",
      "['playing']\n",
      "['playing']\n",
      "----------------------\n",
      "['play']\n",
      "['played']\n",
      "['played']\n",
      "----------------------\n",
      "['surf']\n",
      "['surfing']\n",
      "['surfing']\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from spacy.lemmatizer import VERB,ADJ,NOUN\n",
    "\n",
    "lemmatizer = nlp.vocab.morphology.lemmatizer\n",
    "\n",
    "list1 = [ \"playing\", \"played\", \"surfing\"]\n",
    "\n",
    "for word in list1:\n",
    "    print(lemmatizer(word,VERB))\n",
    "    print(lemmatizer(word,NOUN))\n",
    "    print(lemmatizer(word,ADJ))\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-heart",
   "metadata": {},
   "source": [
    "## Spell Checker\n",
    "\n",
    "**Exercise 1.4**\n",
    "\n",
    "In the following sentences there are some mispelling errors. Can you preprocess them to get rid of them? \n",
    "\n",
    "*N.B. there's no perfect spell-checker. Don't waste time on this. But be aware that it can be useful sometimes.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caroline-agency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:10:59.239954Z",
     "start_time": "2021-03-30T20:10:59.087475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really like this exercise\n",
      "tis sentences are surely writer by an italian\n",
      "lets fix thissssss\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"i realy like this exerxise\", \n",
    "             \"tis sentences are surely writen by an italian\",\n",
    "             \"lets fix thissssss\"\n",
    "            ]\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "for sent in sentences:\n",
    "    print(spell(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-imperial",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "**Exercise 1.5 (★☆☆)**\n",
    "\n",
    "The training of TAs to survive the first two weeks at Strive School consists of the following sets:\n",
    "\n",
    "- 1000 reps of \"Did you google it?\"\n",
    "- 1000 reps of \"Did you search it on Google already?\"\n",
    "\n",
    "Use spaCy to explain the difference of the word \"google\" in the two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "respiratory-priest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:57:52.063503Z",
     "start_time": "2021-03-31T04:57:51.819028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google ----> VERB -----> VB ------>verb, base form\n",
      "Google ----> PROPN -----> NNP ------>noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Did you google it?\",\n",
    "             \"Did you search it on Google already?\"]\n",
    "\n",
    "for sent in sentences:\n",
    "    texts = nlp(sent)\n",
    "    for token in texts:\n",
    "        if token.text.lower() == 'google':\n",
    "            print(f'{token} ----> {token.pos_} -----> {token.tag_} ------>{spacy.explain(token.tag_)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-iceland",
   "metadata": {},
   "source": [
    "**Exercise 1.5 (★★☆)**\n",
    "\n",
    "Get the frequencies of the POS tags in the example sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "rational-xerox",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:17:13.245020Z",
     "start_time": "2021-03-31T05:17:13.220428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 stands for DET     : 3\n",
      "87 stands for AUX     : 1\n",
      "92 stands for NOUN    : 3\n",
      "97 stands for PUNCT   : 2\n",
      "103 stands for SPACE   : 1\n",
      "96 stands for PROPN   : 2\n",
      "85 stands for ADP     : 1\n",
      "95 stands for PRON    : 1\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"This is an example sentence.\n",
    "            Count the POS tags in it.\"\"\"\n",
    "\n",
    "nlp_sentence = nlp(sentence)\n",
    "\n",
    "num_positions = nlp_sentence.count_by(spacy.attrs.POS)\n",
    "\n",
    "for ID, frequency in num_positions.items():\n",
    "    print(f\"{ID} stands for {nlp_sentence.vocab[ID].text:{8}}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-label",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:09:39.399233Z",
     "start_time": "2021-03-31T05:09:39.364673Z"
    }
   },
   "source": [
    "**Exercise 1.7 (★★★)**\n",
    "\n",
    "(This exercises requires many steps in Pandas, no unique solution. You can hard code the name of the columns for this example if you get stuck.)\n",
    "\n",
    "Loading 10 tweets from the twitter datasets, create a dataframe containing the frequencies of each POS per tweet (see example).\n",
    "\n",
    "N.B. The column names must be the tags not the indices of the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fifth-dispute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.616337Z",
     "start_time": "2021-03-31T06:16:19.498649Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/stock_data.csv\")\n",
    "\n",
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "outstanding-commonwealth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.660774Z",
     "start_time": "2021-03-31T06:16:19.656353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1\n",
       "5                                  PGNX  Over 3.04            1\n",
       "6  AAP - user if so then the current downtrend wi...         -1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "8  GOOG - ower trend line channel test & volume s...          1\n",
       "9             AAP will watch tomorrow for ONG entry.          1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "upset-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{92: 7, 85: 1, 90: 1, 96: 7, 103: 1, 93: 2, 89: 1, 97: 1, 100: 1}\n",
      "{92: 6, 97: 4, 96: 5, 93: 2, 85: 2, 90: 2, 99: 1, 86: 1, 103: 2}\n",
      "{92: 4, 95: 2, 100: 2, 87: 2, 84: 3, 94: 1, 96: 2, 97: 5, 98: 2, 90: 2, 85: 1, 89: 1}\n",
      "{96: 1, 85: 1, 93: 1, 103: 1}\n",
      "{96: 1, 103: 2, 85: 1, 93: 1}\n",
      "{96: 1, 103: 2, 85: 1, 93: 1}\n",
      "{92: 7, 97: 5, 98: 1, 86: 4, 90: 2, 84: 3, 100: 2, 85: 1}\n",
      "{96: 10, 94: 1, 84: 1, 92: 3, 97: 1, 103: 1}\n",
      "{92: 6, 97: 2, 96: 2, 89: 1, 103: 1}\n",
      "{96: 2, 100: 2, 92: 2, 85: 1, 97: 1}\n"
     ]
    }
   ],
   "source": [
    "for text in df.Text:\n",
    "    tweet = nlp(text).count_by(spacy.attrs.POS)\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "christian-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kickers on my watchlist XIDE TIT SOQ PNK CPW BPZ AJ  trade method 1 or method 2, see prev posts\n",
      "{92: 7, 85: 1, 90: 1, 96: 7, 103: 1, 93: 2, 89: 1, 97: 1, 100: 1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-ed5012102bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "#dictt = {}\n",
    "\n",
    "for text in df.Text:\n",
    "    print(text)\n",
    "    tweet = nlp(text).count_by(spacy.attrs.POS)\n",
    "    print(tweet)\n",
    "    for ID, frequency in tweet.items():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "median-discrimination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:26:12.875138Z",
     "start_time": "2021-03-31T05:26:12.865565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kickers on my watchlist XIDE TIT SOQ PNK CPW BPZ AJ  trade method 1 or method 2, see prev posts\n",
      "{92: 7, 85: 1, 90: 1, 96: 7, 103: 1, 93: 2, 89: 1, 97: 1, 100: 1}\n",
      "7\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "user: AAP MOVIE. 55% return for the FEA/GEED indicator just 15 trades for the year.  AWESOME.  \n",
      "{92: 6, 97: 4, 96: 5, 93: 2, 85: 2, 90: 2, 99: 1, 86: 1, 103: 2}\n",
      "6\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "user I'd be afraid to short AMZN - they are looking like a near-monopoly in eBooks and infrastructure-as-a-service\n",
      "{92: 4, 95: 2, 100: 2, 87: 2, 84: 3, 94: 1, 96: 2, 97: 5, 98: 2, 90: 2, 85: 1, 89: 1}\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "MNTA Over 12.00  \n",
      "{96: 1, 85: 1, 93: 1, 103: 1}\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "OI  Over 21.37  \n",
      "{96: 1, 103: 2, 85: 1, 93: 1}\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "PGNX  Over 3.04  \n",
      "{96: 1, 103: 2, 85: 1, 93: 1}\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "AAP - user if so then the current downtrend will break. Otherwise just a short-term correction in med-term downtrend.\n",
      "{92: 7, 97: 5, 98: 1, 86: 4, 90: 2, 84: 3, 100: 2, 85: 1}\n",
      "7\n",
      "5\n",
      "1\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "Monday's relative weakness. NYX WIN TIE TAP ICE INT BMC AON C CHK BIIB  \n",
      "{96: 10, 94: 1, 84: 1, 92: 3, 97: 1, 103: 1}\n",
      "10\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "GOOG - ower trend line channel test & volume support.   \n",
      "{92: 6, 97: 2, 96: 2, 89: 1, 103: 1}\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "AAP will watch tomorrow for ONG entry.\n",
      "{96: 2, 100: 2, 92: 2, 85: 1, 97: 1}\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "#dictt = {}\n",
    "\n",
    "for text in df.Text:\n",
    "    print(text)\n",
    "    tweet = nlp(text).count_by(spacy.attrs.POS)\n",
    "    print(tweet)\n",
    "    for ID, frequency in tweet.items():\n",
    "        dict[ID] = frequency\n",
    "        print(dict[ID])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "sized-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOUN': 2,\n",
       " 'ADP': 2,\n",
       " 'DET': 2,\n",
       " 'PROPN': 2,\n",
       " 'SPACE': 2,\n",
       " 'NUM': 2,\n",
       " 'CCONJ': 2,\n",
       " 'PUNCT': 2,\n",
       " 'VERB': 2,\n",
       " 'SYM': 2,\n",
       " 'ADV': 2,\n",
       " 'PRON': 2,\n",
       " 'AUX': 2,\n",
       " 'ADJ': 2,\n",
       " 'PART': 2,\n",
       " 'SCONJ': 2}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = nlp(text).vocab[ID].text\n",
    "        if ID not in columns:\n",
    "            columns.append(ID)\n",
    "            print(type(frequency))\n",
    "        else:\n",
    "            pass\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "collective-missouri",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.001480Z",
     "start_time": "2021-03-31T05:50:56.992453Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.zeros((10,len(columns)+1))\n",
    "data = pd.DataFrame(array, columns=[\"text\", *columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sublime-trade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.097425Z",
     "start_time": "2021-03-31T05:50:57.080979Z"
    }
   },
   "outputs": [],
   "source": [
    "data['text'] = df['Text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "designed-mobile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.313768Z",
     "start_time": "2021-03-31T05:50:57.211856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SYM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  NOUN  ADP  DET  PROPN  \\\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...   0.0  0.0  0.0    0.0   \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...   0.0  0.0  0.0    0.0   \n",
       "2  user I'd be afraid to short AMZN - they are lo...   0.0  0.0  0.0    0.0   \n",
       "3                                  MNTA Over 12.00     0.0  0.0  0.0    0.0   \n",
       "4                                   OI  Over 21.37     0.0  0.0  0.0    0.0   \n",
       "5                                  PGNX  Over 3.04     0.0  0.0  0.0    0.0   \n",
       "6  AAP - user if so then the current downtrend wi...   0.0  0.0  0.0    0.0   \n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...   0.0  0.0  0.0    0.0   \n",
       "8  GOOG - ower trend line channel test & volume s...   0.0  0.0  0.0    0.0   \n",
       "9             AAP will watch tomorrow for ONG entry.   0.0  0.0  0.0    0.0   \n",
       "\n",
       "   SPACE  NUM  CCONJ  PUNCT  VERB  SYM  ADV  PRON  AUX  ADJ  PART  SCONJ  \n",
       "0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "1    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "2    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "3    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "4    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "5    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "6    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "7    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "8    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  \n",
       "9    0.0  0.0    0.0    0.0   0.0  0.0  0.0   0.0  0.0  0.0   0.0    0.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-allowance",
   "metadata": {},
   "source": [
    "## Named Entities Recognition\n",
    "\n",
    "**Exercise 1.8**\n",
    "\n",
    "In the Twitter dataset sample above, count how many entities are in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "smooth-chrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:19:13.644167Z",
     "start_time": "2021-03-31T06:19:13.559490Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "list1 = []\n",
    "for text in df.Text:\n",
    "    entss = []\n",
    "    for ent in nlp(text).ents:\n",
    "        entss.append(ent)\n",
    "    list1.append(len(entss))\n",
    "    \n",
    "df[\"ents\"] = list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "noticed-honor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:11.584150Z",
     "start_time": "2021-03-31T06:18:11.571558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  ents\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1     3\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1     5\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1     1\n",
       "3                                  MNTA Over 12.00            1     1\n",
       "4                                   OI  Over 21.37            1     1\n",
       "5                                  PGNX  Over 3.04            1     2\n",
       "6  AAP - user if so then the current downtrend wi...         -1     1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1     3\n",
       "8  GOOG - ower trend line channel test & volume s...          1     1\n",
       "9             AAP will watch tomorrow for ONG entry.          1     3"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-method",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:48.877669Z",
     "start_time": "2021-03-31T06:18:48.859874Z"
    }
   },
   "source": [
    "**Exercise 1.9**\n",
    "\n",
    "In the Twitter dataset sample above, create an extra column with the name of the Organization entities in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "phantom-ocean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['AAP MOVIE', 'FEA/GEED'],\n",
       " ['eBooks'],\n",
       " [],\n",
       " [],\n",
       " ['PGNX'],\n",
       " ['AAP'],\n",
       " ['NYX'],\n",
       " ['GOOG'],\n",
       " ['AAP', 'ONG']]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list3 =[]\n",
    "for line in df.Text:\n",
    "    lineLength = 0\n",
    "    counter = 0\n",
    "    invalidText = False\n",
    "    for word in nlp(line).ents:\n",
    "        lineLength +=1\n",
    "        if word.label_ != \"ORG\":\n",
    "            counter +=1\n",
    "    if lineLength == counter:\n",
    "        invalidText = True\n",
    "    if invalidText:\n",
    "        list3.append([])\n",
    "    else:\n",
    "        list4=[]\n",
    "        for word in nlp(line).ents:\n",
    "            if word.label_ == 'ORG':\n",
    "                list4.append(word.text)\n",
    "        list3.append(list4)\n",
    "list3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cubic-favor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:50.058745Z",
     "start_time": "2021-03-31T06:20:49.970719Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Organizations\"] = list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "illegal-monthly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:51.522613Z",
     "start_time": "2021-03-31T06:20:51.500337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ents</th>\n",
       "      <th>Organizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[AAP MOVIE, FEA/GEED]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[eBooks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[PGNX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[AAP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>[NYX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[GOOG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[AAP, ONG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  ents  \\\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1     3   \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1     5   \n",
       "2  user I'd be afraid to short AMZN - they are lo...          1     1   \n",
       "3                                  MNTA Over 12.00            1     1   \n",
       "4                                   OI  Over 21.37            1     1   \n",
       "5                                  PGNX  Over 3.04            1     2   \n",
       "6  AAP - user if so then the current downtrend wi...         -1     1   \n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1     3   \n",
       "8  GOOG - ower trend line channel test & volume s...          1     1   \n",
       "9             AAP will watch tomorrow for ONG entry.          1     3   \n",
       "\n",
       "           Organizations  \n",
       "0                     []  \n",
       "1  [AAP MOVIE, FEA/GEED]  \n",
       "2               [eBooks]  \n",
       "3                     []  \n",
       "4                     []  \n",
       "5                 [PGNX]  \n",
       "6                  [AAP]  \n",
       "7                  [NYX]  \n",
       "8                 [GOOG]  \n",
       "9             [AAP, ONG]  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-island",
   "metadata": {},
   "source": [
    "## Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-guyana",
   "metadata": {},
   "source": [
    "**Exercise 2.0**\n",
    "\n",
    "You have scraped many websites collecting a list of users but written in many different form: someone has an email like:\n",
    "\n",
    "```\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "```\n",
    "How would you match all of them using a spaCy matcher?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "domestic-footage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:48:55.806530Z",
     "start_time": "2021-03-31T06:48:55.729472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERNAME 1 4 username: antonio\n",
      "USERNAME 5 8 user: antonio.marsella@email.com\n",
      "USERNAME 9 12 USER:antonio\n",
      "USERNAME 13 16 USERNAME: antonio\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "endless-speaker",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
